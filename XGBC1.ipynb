{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FE_data_18-19.csv', index_col=0)\n",
    "\n",
    "# sort by date\n",
    "df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# make date the index\n",
    "df.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['SsMean'] < 250].SsMean.count())\n",
    "print(df.loc[df['SsMean'] > 250].SsMean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target\n",
    "# 0 = less than 250\n",
    "# 1 = over 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat(data):\n",
    "    if data < 250:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['SsMean'].apply(create_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC, no scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off end of 2019 as test set\n",
    "test_size = df.shape[0] - 14\n",
    "train, test = df.iloc[:test_size], df.iloc[test_size:]\n",
    "\n",
    "X_train, X_test = train.drop(labels=['SsMean','logSsMean', 'label'], axis=1), test.drop(labels=['SsMean','logSsMean','label'], axis=1)\n",
    "y_train, y_test = train.label, test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(labels=['SsMean','logSsMean', 'label'], axis=1)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-143-d060a4a4c6ac>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Location'] = le.transform(X_train['Location'])\n",
      "<ipython-input-143-d060a4a4c6ac>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Location'] = le.transform(X_test['Location'])\n"
     ]
    }
   ],
   "source": [
    "# encode location\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train['Location'])\n",
    "X_train['Location'] = le.transform(X_train['Location'])\n",
    "X_test['Location'] = le.transform(X_test['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reneehall/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:01:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xg = xgb.XGBClassifier()\n",
    "xg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.6238532110091743\n",
      "Test auc: 1.0\n",
      "Test auc: 0.7168715846994536\n",
      "Train precision: 1.0\n",
      "Test precision: 0.559322033898305\n",
      "Train recall: 1.0\n",
      "Test recall: 0.6875\n",
      "F1 score train: 1.0\n",
      "F1 score test: 0.6168224299065421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63        61\n",
      "           1       0.56      0.69      0.62        48\n",
      "\n",
      "    accuracy                           0.62       109\n",
      "   macro avg       0.63      0.63      0.62       109\n",
      "weighted avg       0.64      0.62      0.62       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = xg.predict(X_test)\n",
    "y_train_pred = xg.predict(X_train)\n",
    "\n",
    "test_acc = xg.score(X_test, y_test)\n",
    "train_acc = xg.score(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "train_probs = xg.predict_proba(X_train)[:,1]\n",
    "train_auc = roc_auc_score(y_train,train_probs)\n",
    "print('Test auc:', train_auc)\n",
    "test_probs = xg.predict_proba(X_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test,test_probs)\n",
    "print('Test auc:', test_auc)\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "print('Train precision:', train_precision)\n",
    "print('Test precision:', test_precision)\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "print('Train recall:', train_recall)\n",
    "print('Test recall:', test_recall)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score train:', train_f1)\n",
    "print('F1 score test:', test_f1)\n",
    "\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fca03f71820>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(xg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC with scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off end of 2019 as test set\n",
    "test_size = df.shape[0] - 14\n",
    "train, test = df.iloc[:test_size], df.iloc[test_size:]\n",
    "\n",
    "X_train, X_test = train.drop(labels=['SsMean','logSsMean', 'label'], axis=1), test.drop(labels=['SsMean','logSsMean','label'], axis=1)\n",
    "y_train, y_test = train.label, test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(labels=['SsMean','logSsMean', 'label'], axis=1)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-149-b4deb9fd76ad>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Location'] = le.transform(X_train['Location'])\n",
      "<ipython-input-149-b4deb9fd76ad>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Location'] = le.transform(X_test['Location'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# encode location\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train['Location'])\n",
    "X_train['Location'] = le.transform(X_train['Location'])\n",
    "X_test['Location'] = le.transform(X_test['Location'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reneehall/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:05:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier()\n",
    "xg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.6330275229357798\n",
      "Train auc: 1.0\n",
      "Test auc: 0.7223360655737705\n",
      "Train precision: 1.0\n",
      "Test precision: 0.5666666666666667\n",
      "Train recall: 1.0\n",
      "Test recall: 0.7083333333333334\n",
      "F1 score train: 1.0\n",
      "F1 score test: 0.6296296296296297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.64        61\n",
      "           1       0.57      0.71      0.63        48\n",
      "\n",
      "    accuracy                           0.63       109\n",
      "   macro avg       0.64      0.64      0.63       109\n",
      "weighted avg       0.65      0.63      0.63       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xg.predict(X_test)\n",
    "y_train_pred = xg.predict(X_train)\n",
    "\n",
    "test_acc = xg.score(X_test, y_test)\n",
    "train_acc = xg.score(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "train_probs = xg.predict_proba(X_train)[:,1]\n",
    "train_auc = roc_auc_score(y_train,train_probs)\n",
    "print('Train auc:', train_auc)\n",
    "test_probs = xg.predict_proba(X_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test,test_probs)\n",
    "print('Test auc:', test_auc)\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "print('Train precision:', train_precision)\n",
    "print('Test precision:', test_precision)\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "print('Train recall:', train_recall)\n",
    "print('Test recall:', test_recall)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score train:', train_f1)\n",
    "print('F1 score test:', test_f1)\n",
    "\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fca05b2bb50>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(xg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 500+ label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['SsMean'] < 500].SsMean.count())\n",
    "print(df.loc[df['SsMean'] > 500].SsMean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target\n",
    "# 0 = less than 500\n",
    "# 1 = over 500\n",
    "\n",
    "def create_500(data):\n",
    "    if data < 500:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['SsMean'].apply(create_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create balanced dataset\n",
    "class_0 = df.loc[df['label']==0]\n",
    "class_1 = df.loc[df['label']==1]\n",
    "\n",
    "class_1_sample = class_1.sample(n=377, replace=True)\n",
    "\n",
    "bdf = pd.concat([class_0, class_1_sample], axis=0)\n",
    "bdf.sort_values(by='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754, 37)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC, scaling, 500+ label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off end of 2019 as test set\n",
    "test_size = bdf.shape[0] - 14\n",
    "train, test = bdf.iloc[:test_size], bdf.iloc[test_size:]\n",
    "\n",
    "X_train, X_test = train.drop(labels=['SsMean','logSsMean', 'label'], axis=1), test.drop(labels=['SsMean','logSsMean','label'], axis=1)\n",
    "y_train, y_test = train.label, test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bdf.drop(labels=['SsMean','logSsMean', 'label'], axis=1)\n",
    "y = bdf.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-165-86dd1da13430>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Location'] = le.transform(X_train['Location'])\n",
      "<ipython-input-165-86dd1da13430>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Location'] = le.transform(X_test['Location'])\n",
      "/Users/reneehall/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:33:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode location\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train['Location'])\n",
    "X_train['Location'] = le.transform(X_train['Location'])\n",
    "X_test['Location'] = le.transform(X_test['Location'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "xg = xgb.XGBClassifier()\n",
    "xg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.9139072847682119\n",
      "Train auc: 1.0\n",
      "Test auc: 0.9450704225352113\n",
      "Train precision: 1.0\n",
      "Test precision: 0.8717948717948718\n",
      "Train recall: 1.0\n",
      "Test recall: 0.9577464788732394\n",
      "F1 score train: 1.0\n",
      "F1 score test: 0.9127516778523489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92        80\n",
      "           1       0.87      0.96      0.91        71\n",
      "\n",
      "    accuracy                           0.91       151\n",
      "   macro avg       0.92      0.92      0.91       151\n",
      "weighted avg       0.92      0.91      0.91       151\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fca05ae7e20>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = xg.predict(X_test)\n",
    "y_train_pred = xg.predict(X_train)\n",
    "\n",
    "test_acc = xg.score(X_test, y_test)\n",
    "train_acc = xg.score(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "train_probs = xg.predict_proba(X_train)[:,1]\n",
    "train_auc = roc_auc_score(y_train,train_probs)\n",
    "print('Train auc:', train_auc)\n",
    "test_probs = xg.predict_proba(X_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test,test_probs)\n",
    "print('Test auc:', test_auc)\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "print('Train precision:', train_precision)\n",
    "print('Test precision:', test_precision)\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "print('Train recall:', train_recall)\n",
    "print('Test recall:', test_recall)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score train:', train_f1)\n",
    "print('F1 score test:', test_f1)\n",
    "\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)\n",
    "\n",
    "plot_confusion_matrix(xg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC, no scaling, 500+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off end of 2019 as test set\n",
    "test_size = bdf.shape[0] - 14\n",
    "train, test = bdf.iloc[:test_size], bdf.iloc[test_size:]\n",
    "\n",
    "X_train, X_test = train.drop(labels=['SsMean','logSsMean', 'label'], axis=1), test.drop(labels=['SsMean','logSsMean','label'], axis=1)\n",
    "y_train, y_test = train.label, test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bdf.drop(labels=['SsMean','logSsMean', 'label'], axis=1)\n",
    "y = bdf.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-168-1d60d416afa3>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Location'] = le.transform(X_train['Location'])\n",
      "<ipython-input-168-1d60d416afa3>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Location'] = le.transform(X_test['Location'])\n",
      "/Users/reneehall/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:34:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode location\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train['Location'])\n",
    "X_train['Location'] = le.transform(X_train['Location'])\n",
    "X_test['Location'] = le.transform(X_test['Location'])\n",
    "\n",
    "xg = xgb.XGBClassifier()\n",
    "xg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.9072847682119205\n",
      "Train auc: 1.0\n",
      "Test auc: 0.9431338028169014\n",
      "Train precision: 1.0\n",
      "Test precision: 0.8701298701298701\n",
      "Train recall: 1.0\n",
      "Test recall: 0.9436619718309859\n",
      "F1 score train: 1.0\n",
      "F1 score test: 0.9054054054054054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        80\n",
      "           1       0.87      0.94      0.91        71\n",
      "\n",
      "    accuracy                           0.91       151\n",
      "   macro avg       0.91      0.91      0.91       151\n",
      "weighted avg       0.91      0.91      0.91       151\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fca05d33130>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = xg.predict(X_test)\n",
    "y_train_pred = xg.predict(X_train)\n",
    "\n",
    "test_acc = xg.score(X_test, y_test)\n",
    "train_acc = xg.score(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "train_probs = xg.predict_proba(X_train)[:,1]\n",
    "train_auc = roc_auc_score(y_train,train_probs)\n",
    "print('Train auc:', train_auc)\n",
    "test_probs = xg.predict_proba(X_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test,test_probs)\n",
    "print('Test auc:', test_auc)\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "print('Train precision:', train_precision)\n",
    "print('Test precision:', test_precision)\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "print('Train recall:', train_recall)\n",
    "print('Test recall:', test_recall)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score train:', train_f1)\n",
    "print('F1 score test:', test_f1)\n",
    "\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)\n",
    "\n",
    "plot_confusion_matrix(xg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = pd.DataFrame(test)\n",
    "r_df['pred'] = y_pred\n",
    "r_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = r_df[r_df['label'] != r_df['pred']]\n",
    "correct = r_df[r_df['label'] == r_df['pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_df = pd.DataFrame()\n",
    "for i in incorrect.index.tolist():\n",
    "    wrong_df = wrong_df.append(test.iloc[i])\n",
    "    \n",
    "right_df = pd.DataFrame()\n",
    "for i in correct.index.tolist():\n",
    "    right_df = right_df.append(test.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AvgDP', 'AvgDP_1', 'AvgDP_3', 'AvgDP_7', 'AvgRH', 'AvgRH_1', 'AvgRH_3',\n",
       "       'AvgRH_7', 'AvgTemp', 'AvgTemp_1', 'AvgTemp_3', 'AvgTemp_7',\n",
       "       'AvgWindSpeed', 'Date', 'JDay', 'Location', 'MaxTemp', 'MaxTemp_1',\n",
       "       'MaxTemp_3', 'MaxTemp_7', 'MinTemp', 'MinTemp_1', 'MinTemp_3',\n",
       "       'MinTemp_7', 'Precip', 'Precip_1', 'Precip_3', 'Precip_7', 'SsMean',\n",
       "       'SsMean_1', 'SsMean_3', 'SsMean_7', 'YearWeek', 'label', 'logSsMean',\n",
       "       'month', 'precip_3dTotal', 'pred', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgDP_1</th>\n",
       "      <th>AvgDP_3</th>\n",
       "      <th>AvgDP_7</th>\n",
       "      <th>AvgRH_1</th>\n",
       "      <th>AvgRH_3</th>\n",
       "      <th>AvgRH_7</th>\n",
       "      <th>AvgTemp_1</th>\n",
       "      <th>AvgTemp_3</th>\n",
       "      <th>AvgTemp_7</th>\n",
       "      <th>Location</th>\n",
       "      <th>...</th>\n",
       "      <th>MaxTemp_7</th>\n",
       "      <th>MinTemp_1</th>\n",
       "      <th>MinTemp_3</th>\n",
       "      <th>MinTemp_7</th>\n",
       "      <th>Precip_3</th>\n",
       "      <th>Precip_7</th>\n",
       "      <th>SsMean</th>\n",
       "      <th>SsMean_1</th>\n",
       "      <th>SsMean_3</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.10</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>10.282857</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.628571</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>17.757143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.542857</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.266667</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>2379.4</td>\n",
       "      <td>2362.23</td>\n",
       "      <td>863.873333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.88</td>\n",
       "      <td>11.046667</td>\n",
       "      <td>10.605714</td>\n",
       "      <td>83.9</td>\n",
       "      <td>70.733333</td>\n",
       "      <td>64.242857</td>\n",
       "      <td>13.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>17.757143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.528571</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>768.5</td>\n",
       "      <td>2379.40</td>\n",
       "      <td>1629.076667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.88</td>\n",
       "      <td>11.046667</td>\n",
       "      <td>10.605714</td>\n",
       "      <td>83.9</td>\n",
       "      <td>70.733333</td>\n",
       "      <td>64.242857</td>\n",
       "      <td>13.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>17.757143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.528571</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>768.5</td>\n",
       "      <td>2379.40</td>\n",
       "      <td>1629.076667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AvgDP_1    AvgDP_3    AvgDP_7  AvgRH_1    AvgRH_3    AvgRH_7  AvgTemp_1  \\\n",
       "8     11.10  11.800000  10.282857     56.0  58.500000  62.628571       19.9   \n",
       "17     9.88  11.046667  10.605714     83.9  70.733333  64.242857       13.1   \n",
       "20     9.88  11.046667  10.605714     83.9  70.733333  64.242857       13.1   \n",
       "\n",
       "    AvgTemp_3  AvgTemp_7  Location  ...  MaxTemp_7  MinTemp_1  MinTemp_3  \\\n",
       "8        20.1  17.757143       2.0  ...  26.542857       12.9  12.266667   \n",
       "17       16.9  17.757143       2.0  ...  26.528571        7.7  10.366667   \n",
       "20       16.9  17.757143       2.0  ...  26.528571        7.7  10.366667   \n",
       "\n",
       "    MinTemp_7  Precip_3  Precip_7  SsMean  SsMean_1     SsMean_3  pred  \n",
       "8    9.700000  0.866667  0.657143  2379.4   2362.23   863.873333   0.0  \n",
       "17   9.571429  0.866667  0.800000   768.5   2379.40  1629.076667   0.0  \n",
       "20   9.571429  0.866667  0.800000   768.5   2379.40  1629.076667   0.0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['AvgDP_1', 'AvgDP_3', 'AvgDP_7', 'AvgRH_1', 'AvgRH_3',\n",
    "       'AvgRH_7', 'AvgTemp_1', 'AvgTemp_3', 'AvgTemp_7',\n",
    "       'Location', 'MaxTemp_1',\n",
    "       'MaxTemp_3', 'MaxTemp_7', 'MinTemp_1', 'MinTemp_3',\n",
    "       'MinTemp_7', 'Precip_3', 'Precip_7', 'SsMean',\n",
    "       'SsMean_1', 'SsMean_3',\n",
    "       'pred']\n",
    "\n",
    "wrong_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgDP_1</th>\n",
       "      <th>AvgDP_3</th>\n",
       "      <th>AvgDP_7</th>\n",
       "      <th>AvgRH_1</th>\n",
       "      <th>AvgRH_3</th>\n",
       "      <th>AvgRH_7</th>\n",
       "      <th>AvgTemp_1</th>\n",
       "      <th>AvgTemp_3</th>\n",
       "      <th>AvgTemp_7</th>\n",
       "      <th>Location</th>\n",
       "      <th>...</th>\n",
       "      <th>MaxTemp_7</th>\n",
       "      <th>MinTemp_1</th>\n",
       "      <th>MinTemp_3</th>\n",
       "      <th>MinTemp_7</th>\n",
       "      <th>Precip_3</th>\n",
       "      <th>Precip_7</th>\n",
       "      <th>SsMean</th>\n",
       "      <th>SsMean_1</th>\n",
       "      <th>SsMean_3</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.40</td>\n",
       "      <td>12.226667</td>\n",
       "      <td>10.377143</td>\n",
       "      <td>72.5</td>\n",
       "      <td>64.300000</td>\n",
       "      <td>66.885714</td>\n",
       "      <td>16.9</td>\n",
       "      <td>19.366667</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>10.371429</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>2260.510</td>\n",
       "      <td>135.420</td>\n",
       "      <td>595.573333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>11.211429</td>\n",
       "      <td>67.4</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>63.985714</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.266667</td>\n",
       "      <td>18.414286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.628571</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.042857</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>936.380</td>\n",
       "      <td>132.570</td>\n",
       "      <td>1058.526667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.40</td>\n",
       "      <td>12.226667</td>\n",
       "      <td>10.377143</td>\n",
       "      <td>72.5</td>\n",
       "      <td>64.300000</td>\n",
       "      <td>66.885714</td>\n",
       "      <td>16.9</td>\n",
       "      <td>19.366667</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>10.371429</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>2260.510</td>\n",
       "      <td>135.420</td>\n",
       "      <td>595.573333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>11.211429</td>\n",
       "      <td>67.4</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>63.985714</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.266667</td>\n",
       "      <td>18.414286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.628571</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.042857</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>936.380</td>\n",
       "      <td>132.570</td>\n",
       "      <td>1058.526667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.40</td>\n",
       "      <td>12.226667</td>\n",
       "      <td>10.342857</td>\n",
       "      <td>72.5</td>\n",
       "      <td>64.300000</td>\n",
       "      <td>63.714286</td>\n",
       "      <td>16.9</td>\n",
       "      <td>19.366667</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.157143</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>10.071429</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>16864.435</td>\n",
       "      <td>249.440</td>\n",
       "      <td>259.771667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.16</td>\n",
       "      <td>12.620000</td>\n",
       "      <td>10.634286</td>\n",
       "      <td>72.3</td>\n",
       "      <td>64.600000</td>\n",
       "      <td>65.242857</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>17.585714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.771429</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.266667</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>1472.790</td>\n",
       "      <td>308.880</td>\n",
       "      <td>571.583333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.18</td>\n",
       "      <td>12.440000</td>\n",
       "      <td>11.917143</td>\n",
       "      <td>71.4</td>\n",
       "      <td>62.533333</td>\n",
       "      <td>68.800000</td>\n",
       "      <td>17.9</td>\n",
       "      <td>19.933333</td>\n",
       "      <td>18.157143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.871429</td>\n",
       "      <td>11.1</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>11.857143</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>389.480</td>\n",
       "      <td>34.300</td>\n",
       "      <td>53.850000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>11.211429</td>\n",
       "      <td>67.4</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>63.985714</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.266667</td>\n",
       "      <td>18.414286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.628571</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.042857</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>936.380</td>\n",
       "      <td>132.570</td>\n",
       "      <td>1058.526667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.72</td>\n",
       "      <td>12.426667</td>\n",
       "      <td>11.608571</td>\n",
       "      <td>45.6</td>\n",
       "      <td>63.300000</td>\n",
       "      <td>59.757143</td>\n",
       "      <td>21.6</td>\n",
       "      <td>19.766667</td>\n",
       "      <td>19.657143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.814286</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>10.871429</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>84.000</td>\n",
       "      <td>936.380</td>\n",
       "      <td>384.130000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.92</td>\n",
       "      <td>12.206667</td>\n",
       "      <td>11.682857</td>\n",
       "      <td>53.6</td>\n",
       "      <td>67.033333</td>\n",
       "      <td>63.985714</td>\n",
       "      <td>20.2</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>18.885714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.114286</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>11.842857</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>26.930</td>\n",
       "      <td>389.480</td>\n",
       "      <td>145.020000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.10</td>\n",
       "      <td>12.273333</td>\n",
       "      <td>11.131429</td>\n",
       "      <td>56.0</td>\n",
       "      <td>67.533333</td>\n",
       "      <td>62.871429</td>\n",
       "      <td>19.9</td>\n",
       "      <td>18.766667</td>\n",
       "      <td>18.557143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.028571</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>10.314286</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>294.060</td>\n",
       "      <td>1472.790</td>\n",
       "      <td>664.543333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.06</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.825714</td>\n",
       "      <td>57.8</td>\n",
       "      <td>68.833333</td>\n",
       "      <td>61.485714</td>\n",
       "      <td>19.5</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>18.528571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.371429</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>10.414286</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>16864.435</td>\n",
       "      <td>5707.848333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.06</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.825714</td>\n",
       "      <td>57.8</td>\n",
       "      <td>68.833333</td>\n",
       "      <td>61.485714</td>\n",
       "      <td>19.5</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>18.528571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.371429</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>10.414286</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>16864.435</td>\n",
       "      <td>5707.848333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.06</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.574286</td>\n",
       "      <td>57.8</td>\n",
       "      <td>68.833333</td>\n",
       "      <td>63.585714</td>\n",
       "      <td>19.5</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>17.857143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.242857</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>10.428571</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>239.920</td>\n",
       "      <td>2260.510</td>\n",
       "      <td>895.566667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1377.310</td>\n",
       "      <td>239.920</td>\n",
       "      <td>878.616667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1377.310</td>\n",
       "      <td>239.920</td>\n",
       "      <td>878.616667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1377.310</td>\n",
       "      <td>239.920</td>\n",
       "      <td>878.616667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>2054.905</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>6198.995000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.40</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>11.342857</td>\n",
       "      <td>80.5</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>64.357143</td>\n",
       "      <td>13.3</td>\n",
       "      <td>17.133333</td>\n",
       "      <td>18.471429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.485714</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>9.180</td>\n",
       "      <td>26.930</td>\n",
       "      <td>150.236667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.44</td>\n",
       "      <td>10.846667</td>\n",
       "      <td>11.551429</td>\n",
       "      <td>79.7</td>\n",
       "      <td>64.233333</td>\n",
       "      <td>63.971429</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.757143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>10.514286</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>89.860</td>\n",
       "      <td>84.000</td>\n",
       "      <td>384.316667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>2054.905</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>6198.995000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>2054.905</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>6198.995000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.68</td>\n",
       "      <td>9.553333</td>\n",
       "      <td>10.351429</td>\n",
       "      <td>73.4</td>\n",
       "      <td>71.100000</td>\n",
       "      <td>65.900000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>17.171429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.414286</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>9.685714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>44.370</td>\n",
       "      <td>768.500</td>\n",
       "      <td>1836.710000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.32</td>\n",
       "      <td>9.160000</td>\n",
       "      <td>11.248571</td>\n",
       "      <td>70.1</td>\n",
       "      <td>65.133333</td>\n",
       "      <td>64.957143</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.133333</td>\n",
       "      <td>18.257143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.628571</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.766667</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>25.660</td>\n",
       "      <td>89.860</td>\n",
       "      <td>370.080000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.26</td>\n",
       "      <td>9.193333</td>\n",
       "      <td>10.737143</td>\n",
       "      <td>70.8</td>\n",
       "      <td>68.300000</td>\n",
       "      <td>64.257143</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15.533333</td>\n",
       "      <td>17.885714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.414286</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>10.814286</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>49.650</td>\n",
       "      <td>9.180</td>\n",
       "      <td>141.863333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.68</td>\n",
       "      <td>9.553333</td>\n",
       "      <td>10.974286</td>\n",
       "      <td>73.4</td>\n",
       "      <td>71.100000</td>\n",
       "      <td>66.942857</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>17.585714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.271429</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>10.342857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>24.620</td>\n",
       "      <td>2292.600</td>\n",
       "      <td>1353.150000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.10</td>\n",
       "      <td>7.953333</td>\n",
       "      <td>10.654286</td>\n",
       "      <td>58.5</td>\n",
       "      <td>69.433333</td>\n",
       "      <td>64.271429</td>\n",
       "      <td>15.4</td>\n",
       "      <td>14.066667</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.214286</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.533333</td>\n",
       "      <td>9.957143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>15.870</td>\n",
       "      <td>25.660</td>\n",
       "      <td>66.506667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AvgDP_1    AvgDP_3    AvgDP_7  AvgRH_1    AvgRH_3    AvgRH_7  AvgTemp_1  \\\n",
       "0     11.40  12.226667  10.377143     72.5  64.300000  66.885714       16.9   \n",
       "1     12.38  13.333333  11.211429     67.4  65.333333  63.985714       18.9   \n",
       "2     11.40  12.226667  10.377143     72.5  64.300000  66.885714       16.9   \n",
       "3     12.38  13.333333  11.211429     67.4  65.333333  63.985714       18.9   \n",
       "4     11.40  12.226667  10.342857     72.5  64.300000  63.714286       16.9   \n",
       "5     12.16  12.620000  10.634286     72.3  64.600000  65.242857       17.7   \n",
       "6     12.18  12.440000  11.917143     71.4  62.533333  68.800000       17.9   \n",
       "7     12.38  13.333333  11.211429     67.4  65.333333  63.985714       18.9   \n",
       "9     10.72  12.426667  11.608571     45.6  63.300000  59.757143       21.6   \n",
       "10    10.92  12.206667  11.682857     53.6  67.033333  63.985714       20.2   \n",
       "11    11.10  12.273333  11.131429     56.0  67.533333  62.871429       19.9   \n",
       "12    11.06  11.966667  10.825714     57.8  68.833333  61.485714       19.5   \n",
       "13    11.06  11.966667  10.825714     57.8  68.833333  61.485714       19.5   \n",
       "14    11.06  11.966667  10.574286     57.8  68.833333  63.585714       19.5   \n",
       "15     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "16     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "18     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "19     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "21     9.40  10.833333  11.342857     80.5  68.500000  64.357143       13.3   \n",
       "22     9.44  10.846667  11.551429     79.7  64.233333  63.971429       13.5   \n",
       "23     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "24     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "25     7.68   9.553333  10.351429     73.4  71.100000  65.900000       13.0   \n",
       "26     7.32   9.160000  11.248571     70.1  65.133333  64.957143       13.3   \n",
       "27     7.26   9.193333  10.737143     70.8  68.300000  64.257143       13.1   \n",
       "28     7.68   9.553333  10.974286     73.4  71.100000  66.942857       13.0   \n",
       "29     7.10   7.953333  10.654286     58.5  69.433333  64.271429       15.4   \n",
       "\n",
       "    AvgTemp_3  AvgTemp_7  Location  ...  MaxTemp_7  MinTemp_1  MinTemp_3  \\\n",
       "0   19.366667  17.000000       4.0  ...  24.800000        8.7  12.066667   \n",
       "1   20.266667  18.414286       5.0  ...  26.628571        9.4  11.966667   \n",
       "2   19.366667  17.000000       4.0  ...  24.800000        8.7  12.066667   \n",
       "3   20.266667  18.414286       5.0  ...  26.628571        9.4  11.966667   \n",
       "4   19.366667  17.600000       3.0  ...  26.157143        8.7  12.066667   \n",
       "5   19.700000  17.585714       1.0  ...  25.771429       10.5  12.266667   \n",
       "6   19.933333  18.157143       0.0  ...  25.871429       11.1  12.833333   \n",
       "7   20.266667  18.414286       5.0  ...  26.628571        9.4  11.966667   \n",
       "9   19.766667  19.657143       5.0  ...  27.814286       14.2  12.766667   \n",
       "10  18.800000  18.885714       0.0  ...  27.114286       12.9  12.533333   \n",
       "11  18.766667  18.557143       1.0  ...  27.028571       12.9  12.100000   \n",
       "12  18.200000  18.528571       3.0  ...  27.371429       11.3  11.166667   \n",
       "13  18.200000  18.528571       3.0  ...  27.371429       11.3  11.166667   \n",
       "14  18.200000  17.857143       4.0  ...  26.242857       11.3  11.166667   \n",
       "15  16.700000  17.957143       4.0  ...  26.257143        7.6   9.200000   \n",
       "16  16.700000  17.957143       4.0  ...  26.257143        7.6   9.200000   \n",
       "18  16.700000  17.957143       4.0  ...  26.257143        7.6   9.200000   \n",
       "19  16.700000  17.957143       3.0  ...  26.257143        7.6   9.200000   \n",
       "21  17.133333  18.471429       0.0  ...  26.485714        8.0  10.666667   \n",
       "22  18.000000  18.757143       5.0  ...  26.300000        6.8  10.133333   \n",
       "23  16.700000  17.957143       3.0  ...  26.257143        7.6   9.200000   \n",
       "24  16.700000  17.957143       3.0  ...  26.257143        7.6   9.200000   \n",
       "25  15.333333  17.171429       2.0  ...  25.414286        7.3   9.300000   \n",
       "26  16.133333  18.257143       5.0  ...  25.628571        8.3   9.766667   \n",
       "27  15.533333  17.885714       0.0  ...  25.414286        6.0   8.966667   \n",
       "28  15.333333  17.585714       1.0  ...  25.271429        7.3   9.300000   \n",
       "29  14.066667  17.800000       5.0  ...  25.214286        4.5   6.533333   \n",
       "\n",
       "    MinTemp_7  Precip_3  Precip_7     SsMean   SsMean_1     SsMean_3  pred  \n",
       "0   10.371429  0.966667  1.071429   2260.510    135.420   595.573333   1.0  \n",
       "1   10.042857  1.166667  0.714286    936.380    132.570  1058.526667   1.0  \n",
       "2   10.371429  0.966667  1.071429   2260.510    135.420   595.573333   1.0  \n",
       "3   10.042857  1.166667  0.714286    936.380    132.570  1058.526667   1.0  \n",
       "4   10.071429  0.966667  0.528571  16864.435    249.440   259.771667   1.0  \n",
       "5    9.700000  0.866667  0.657143   1472.790    308.880   571.583333   1.0  \n",
       "6   11.857143  1.333333  0.771429    389.480     34.300    53.850000   0.0  \n",
       "7   10.042857  1.166667  0.714286    936.380    132.570  1058.526667   1.0  \n",
       "9   10.871429  0.766667  0.571429     84.000    936.380   384.130000   0.0  \n",
       "10  11.842857  1.366667  0.671429     26.930    389.480   145.020000   0.0  \n",
       "11  10.314286  0.433333  0.614286    294.060   1472.790   664.543333   0.0  \n",
       "12  10.414286  0.966667  0.414286   1483.110  16864.435  5707.848333   1.0  \n",
       "13  10.414286  0.966667  0.414286   1483.110  16864.435  5707.848333   1.0  \n",
       "14  10.428571  0.966667  0.528571    239.920   2260.510   895.566667   0.0  \n",
       "15  10.242857  0.000000  0.414286   1377.310    239.920   878.616667   1.0  \n",
       "16  10.242857  0.000000  0.414286   1377.310    239.920   878.616667   1.0  \n",
       "18  10.242857  0.000000  0.414286   1377.310    239.920   878.616667   1.0  \n",
       "19  10.242857  0.000000  0.414286   2054.905   1483.110  6198.995000   1.0  \n",
       "21  11.285714  0.533333  0.885714      9.180     26.930   150.236667   0.0  \n",
       "22  10.514286  0.266667  0.542857     89.860     84.000   384.316667   0.0  \n",
       "23  10.242857  0.000000  0.414286   2054.905   1483.110  6198.995000   1.0  \n",
       "24  10.242857  0.000000  0.414286   2054.905   1483.110  6198.995000   1.0  \n",
       "25   9.685714  1.000000  0.971429     44.370    768.500  1836.710000   0.0  \n",
       "26  10.300000  0.266667  0.614286     25.660     89.860   370.080000   0.0  \n",
       "27  10.814286  0.733333  0.885714     49.650      9.180   141.863333   0.0  \n",
       "28  10.342857  1.000000  0.942857     24.620   2292.600  1353.150000   0.0  \n",
       "29   9.957143  0.333333  0.642857     15.870     25.660    66.506667   0.0  \n",
       "\n",
       "[27 rows x 22 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighthouse",
   "language": "python",
   "name": "lighthouse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
