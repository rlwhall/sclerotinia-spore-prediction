{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather data from https://agriculture.alberta.ca/acis/weather-data-viewer.jsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_and_location2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FieldID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year_x</th>\n",
       "      <th>JDay</th>\n",
       "      <th>SsCtMean</th>\n",
       "      <th>SsCtSD</th>\n",
       "      <th>SsMean</th>\n",
       "      <th>logSsMean</th>\n",
       "      <th>TtCt</th>\n",
       "      <th>TtSD</th>\n",
       "      <th>...</th>\n",
       "      <th>Year_y</th>\n",
       "      <th>SamplerNo</th>\n",
       "      <th>CropType</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Region</th>\n",
       "      <th>Province</th>\n",
       "      <th>SamplerPresent</th>\n",
       "      <th>SamplerType</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1904</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019</td>\n",
       "      <td>186</td>\n",
       "      <td>37.15</td>\n",
       "      <td>0.63</td>\n",
       "      <td>6.51</td>\n",
       "      <td>0.875640</td>\n",
       "      <td>23.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.869673</td>\n",
       "      <td>-112.076528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1904</td>\n",
       "      <td>2019-07-06</td>\n",
       "      <td>2019</td>\n",
       "      <td>187</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.869673</td>\n",
       "      <td>-112.076528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1904</td>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>2019</td>\n",
       "      <td>188</td>\n",
       "      <td>36.85</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7.57</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.869673</td>\n",
       "      <td>-112.076528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1904</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>189</td>\n",
       "      <td>38.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.521138</td>\n",
       "      <td>24.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.869673</td>\n",
       "      <td>-112.076528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1904</td>\n",
       "      <td>2019-07-09</td>\n",
       "      <td>2019</td>\n",
       "      <td>190</td>\n",
       "      <td>33.44</td>\n",
       "      <td>0.25</td>\n",
       "      <td>65.06</td>\n",
       "      <td>1.819939</td>\n",
       "      <td>24.41</td>\n",
       "      <td>0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.869673</td>\n",
       "      <td>-112.076528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  FieldID        Date  Year_x  JDay SsCtMean  SsCtSD  SsMean  logSsMean  \\\n",
       "0    1904  2019-07-05    2019   186    37.15    0.63    6.51   0.875640   \n",
       "1    1904  2019-07-06    2019   187    40.00    0.00    0.00   0.000000   \n",
       "2    1904  2019-07-07    2019   188    36.85    0.25    7.57   0.932981   \n",
       "3    1904  2019-07-08    2019   189    38.80    0.76    2.32   0.521138   \n",
       "4    1904  2019-07-09    2019   190    33.44    0.25   65.06   1.819939   \n",
       "\n",
       "    TtCt  TtSD  ...  Year_y  SamplerNo  CropType  Crop    Region  Province  \\\n",
       "0  23.60  0.10  ...  2019.0        NaN      Bean  Bean  Vauxhall   Alberta   \n",
       "1  23.29  0.07  ...  2019.0        NaN      Bean  Bean  Vauxhall   Alberta   \n",
       "2  23.40  0.07  ...  2019.0        NaN      Bean  Bean  Vauxhall   Alberta   \n",
       "3  24.03  0.05  ...  2019.0        NaN      Bean  Bean  Vauxhall   Alberta   \n",
       "4  24.41  0.08  ...  2019.0        NaN      Bean  Bean  Vauxhall   Alberta   \n",
       "\n",
       "   SamplerPresent  SamplerType        Lat        Long  \n",
       "0             Yes      Burkard  49.869673 -112.076528  \n",
       "1             Yes      Burkard  49.869673 -112.076528  \n",
       "2             Yes      Burkard  49.869673 -112.076528  \n",
       "3             Yes      Burkard  49.869673 -112.076528  \n",
       "4             Yes      Burkard  49.869673 -112.076528  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FieldID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year_x</th>\n",
       "      <th>JDay</th>\n",
       "      <th>SsCtMean</th>\n",
       "      <th>SsCtSD</th>\n",
       "      <th>SsMean</th>\n",
       "      <th>logSsMean</th>\n",
       "      <th>TtCt</th>\n",
       "      <th>TtSD</th>\n",
       "      <th>...</th>\n",
       "      <th>Year_y</th>\n",
       "      <th>SamplerNo</th>\n",
       "      <th>CropType</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Region</th>\n",
       "      <th>Province</th>\n",
       "      <th>SamplerPresent</th>\n",
       "      <th>SamplerType</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>2042</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2020</td>\n",
       "      <td>239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15165.722660</td>\n",
       "      <td>4.181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean disease nursery</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Lethbridge</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.70232</td>\n",
       "      <td>-112.75915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2042</td>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>2020</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8115.201511</td>\n",
       "      <td>3.909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean disease nursery</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Lethbridge</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.70232</td>\n",
       "      <td>-112.75915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2042</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>2020</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3191.067340</td>\n",
       "      <td>3.504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean disease nursery</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Lethbridge</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.70232</td>\n",
       "      <td>-112.75915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>2042</td>\n",
       "      <td>2020-08-29</td>\n",
       "      <td>2020</td>\n",
       "      <td>242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2569.229289</td>\n",
       "      <td>3.410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean disease nursery</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Lethbridge</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.70232</td>\n",
       "      <td>-112.75915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>2042</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2020</td>\n",
       "      <td>243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>729.416321</td>\n",
       "      <td>2.864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bean disease nursery</td>\n",
       "      <td>Bean</td>\n",
       "      <td>Lethbridge</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Burkard</td>\n",
       "      <td>49.70232</td>\n",
       "      <td>-112.75915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FieldID       Date  Year_x  JDay SsCtMean  SsCtSD        SsMean  \\\n",
       "746    2042 2020-08-26    2020   239      NaN     NaN  15165.722660   \n",
       "747    2042 2020-08-27    2020   240      NaN     NaN   8115.201511   \n",
       "748    2042 2020-08-28    2020   241      NaN     NaN   3191.067340   \n",
       "749    2042 2020-08-29    2020   242      NaN     NaN   2569.229289   \n",
       "750    2042 2020-08-30    2020   243      NaN     NaN    729.416321   \n",
       "\n",
       "     logSsMean  TtCt  TtSD  ...  Year_y  SamplerNo              CropType  \\\n",
       "746      4.181   NaN   NaN  ...  2020.0        NaN  Bean disease nursery   \n",
       "747      3.909   NaN   NaN  ...  2020.0        NaN  Bean disease nursery   \n",
       "748      3.504   NaN   NaN  ...  2020.0        NaN  Bean disease nursery   \n",
       "749      3.410   NaN   NaN  ...  2020.0        NaN  Bean disease nursery   \n",
       "750      2.864   NaN   NaN  ...  2020.0        NaN  Bean disease nursery   \n",
       "\n",
       "     Crop      Region  Province  SamplerPresent  SamplerType       Lat  \\\n",
       "746  Bean  Lethbridge   Alberta             Yes      Burkard  49.70232   \n",
       "747  Bean  Lethbridge   Alberta             Yes      Burkard  49.70232   \n",
       "748  Bean  Lethbridge   Alberta             Yes      Burkard  49.70232   \n",
       "749  Bean  Lethbridge   Alberta             Yes      Burkard  49.70232   \n",
       "750  Bean  Lethbridge   Alberta             Yes      Burkard  49.70232   \n",
       "\n",
       "          Long  \n",
       "746 -112.75915  \n",
       "747 -112.75915  \n",
       "748 -112.75915  \n",
       "749 -112.75915  \n",
       "750 -112.75915  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Vauxhall', 'Cranford', 'Taber', '1919', '1920', '1921', '1906',\n",
       "       '1910', '1922', '1904', '1917', '1915', '2007', '2006', '2042',\n",
       "       '2001', '2004'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2018 dates start on June 13, 2020 dates end on Aug 30\n",
    "df2['FieldID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vauxhall = FieldID 1814\n",
    "# Taber = FieldID 1804\n",
    "# Cranford = FieldID 1810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rolling hills weather: 'vauxhall' \\\n",
    "barnwell weather: 'cranford' \\\n",
    "lethbridge weather: 1919, 1920, 1921, 1922, 2042 \\\n",
    "vauxhall weather: 1906, 1910, 2007 \\\n",
    "fincastle weather: 1904 \\\n",
    "bow weather = 1917, 2006, 2004, 'taber' \\\n",
    "bow north weather = 1915 \\\n",
    "grassy lake weather: 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dew point function\n",
    "def dew_point(RH, Temp):\n",
    "    a = Temp\n",
    "    b = ((100-RH)/5)\n",
    "    DP = a-b\n",
    "    return DP\n",
    "\n",
    "def rolling_mean(data, col):\n",
    "    # -1 day data\n",
    "    name1 = col + '_1'\n",
    "    # shift by 1\n",
    "    lag1 = data[col].shift(1)\n",
    "    # assign to column  \n",
    "    data[name1] = lag1\n",
    "    \n",
    "    # -3 day mean\n",
    "    name3 = col + '_3'\n",
    "    # assign mean to column\n",
    "    window3 = lag1.rolling(window=3).mean()\n",
    "    data[name3] = window3\n",
    "    \n",
    "    # 7 day rolling mean leads to a lot of lost values\n",
    "    # -7 day mean\n",
    "    name7 = col + '_7'\n",
    "    # assign mean to column\n",
    "    window7 = lag1.rolling(window=7).mean()\n",
    "    data[name7] = window7\n",
    "    \n",
    "    # fill NaN's with june mean info so that we can keep as much data as possible\n",
    "   # data[name1] = data[name1].fillna(value=data.iloc[1:7][name1].mean())\n",
    "    #data[name3] = data[name3].fillna(value=data.iloc[6:10][name3].mean())\n",
    "    #data[name7] = data[name7].fillna(value=data.iloc[13:20][name7].mean())\n",
    "    \n",
    "    # return new dataframe\n",
    "    return data\n",
    "\n",
    "def rolling_sum(data, col):\n",
    "    # -1 day data\n",
    "    name1 = col + 'Sum_1'\n",
    "    # shift by 1\n",
    "    lag1 = data[col].shift(1)\n",
    "    # assign to column  \n",
    "    data[name1] = lag1\n",
    "    \n",
    "    # -3 day mean\n",
    "    name3 = col + 'Sum_3'\n",
    "    # assign mean to column\n",
    "    window3 = lag1.rolling(window=3).sum()\n",
    "    data[name3] = window3\n",
    "    \n",
    "    # 7 day rolling mean leads to a lot of lost values\n",
    "    # -7 day mean\n",
    "    name7 = col + 'Sum_7'\n",
    "    # assign mean to column\n",
    "    window7 = lag1.rolling(window=7).sum()\n",
    "    data[name7] = window7\n",
    "    \n",
    "    # fill NaN's with june mean info so that we can keep as much data as possible\n",
    "   # data[name1] = data[name1].fillna(value=data.iloc[1:7][name1].mean())\n",
    "    #data[name3] = data[name3].fillna(value=data.iloc[6:10][name3].mean())\n",
    "    #data[name7] = data[name7].fillna(value=data.iloc[13:20][name7].mean())\n",
    "    \n",
    "    # return new dataframe\n",
    "    return data\n",
    "\n",
    "def temp_DP(data, col):\n",
    "    name = col + '_uDP'\n",
    "    data[name] = data.apply(lambda x: 1 if x[col] <= x['MeanDP'] else 0, axis = 1)\n",
    "    return data\n",
    "\n",
    "def cool_temp(data, col):\n",
    "    name = col + '_u20'\n",
    "    data[name] = data[col].apply(lambda x: 1 if x <= 20 else 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap all feature engineering into 1 function\n",
    "def engineer(data):\n",
    "    # drop extra columns\n",
    "    to_drop = ['Air Temp. Min. Source Flag', 'Air Temp. Min. Record Completeness (%)',\n",
    "       'Air Temp. Max. Source Flag','Air Temp. Max. Record Completeness (%)', \n",
    "       'Air Temp. Avg. Source Flag', 'Air Temp. Avg. Record Completeness (%)',\n",
    "       'Humidity Avg. Source Flag','Humidity Avg. Record Completeness (%)', \n",
    "       'Precip. Accumulated Source Flag', 'Precip. Accumulated Comment','Precip. Source Flag', 'Precip. Comment',\n",
    "        'Wind Speed 2 m Avg. Source Flag','Wind Speed 2 m Avg. Record Completeness (%)',\n",
    "        'Wind Speed 10 m Avg. Source Flag','Wind Speed 10 m Avg. Record Completeness (%)',\n",
    "        'Wind Dir. 10 m Avg. Source Flag','Wind Dir. 10 m Avg. Record Completeness (%)',\n",
    "       'Frost Probability 0�C Source Flag','Frost Probability 0�C Record Completeness (%)', \n",
    "        'Precip. Accumulated (mm)']\n",
    "    data.drop(labels=to_drop, axis=1, inplace=True)\n",
    "    # rename columns\n",
    "    data.columns = ['Station','Date','MinTemp','MaxTemp','MeanTemp','MeanRH','Precip','Wind2','Wind10','Wind10Dir','Frost']\n",
    "    # turn date column into datetime\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    # create dew point feature\n",
    "    data['MeanDP'] = dew_point(data['MeanRH'], data['MeanTemp'])\n",
    "    # create counts below dewpoint and 20 degrees\n",
    "    temp_cols = ['MinTemp', 'MaxTemp', 'MeanTemp']\n",
    "    for col in temp_cols:\n",
    "        data = temp_DP(data, col)\n",
    "        data = cool_temp(data, col)\n",
    "    # calculate rolling means and sums\n",
    "    roll_means = ['MinTemp','MaxTemp','MeanTemp','MeanRH','Precip','Wind2','Wind10','Wind10Dir','Frost','MeanDP']\n",
    "    roll_sums = ['Precip','MinTemp_uDP','MaxTemp_uDP','MeanTemp_uDP', 'MinTemp_u20', 'MaxTemp_u20', 'MeanTemp_u20']\n",
    "    for col in roll_means:\n",
    "        data = rolling_mean(data, col)\n",
    "    for col in roll_sums:\n",
    "        data = rolling_sum(data, col)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_hills1 = pd.read_csv('rolling_hills_18-19.csv')\n",
    "rolling_hills2 = pd.read_csv('rolling_hills_20.csv')\n",
    "rolling_hills = pd.concat([rolling_hills1, rolling_hills2], ignore_index=True)\n",
    "weather_dfs.append(rolling_hills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "barnwell1 = pd.read_csv('barnwell_18-19.csv')\n",
    "barnwell2 = pd.read_csv('barnwell_20.csv')\n",
    "barnwell = pd.concat([barnwell1, barnwell2], ignore_index=True)\n",
    "weather_dfs.append(barnwell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "lethbridge1 = pd.read_csv('lethbridge_18-19.csv')\n",
    "lethbridge2 = pd.read_csv('lethbridge_20.csv')\n",
    "lethbridge = pd.concat([lethbridge1, lethbridge2], ignore_index=True)\n",
    "weather_dfs.append(lethbridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "vauxhall1 = pd.read_csv('vauxhall_18-19.csv')\n",
    "vauxhall2 = pd.read_csv('vauxhall_20.csv')\n",
    "vauxhall = pd.concat([vauxhall1, vauxhall2], ignore_index=True)\n",
    "weather_dfs.append(vauxhall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "fincastle1 = pd.read_csv('fincastle_18-19.csv')\n",
    "fincastle2 = pd.read_csv('fincastle_20.csv')\n",
    "fincastle = pd.concat([fincastle1, fincastle2], ignore_index=True)\n",
    "weather_dfs.append(fincastle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow1 = pd.read_csv('bow_18-19.csv')\n",
    "bow2 = pd.read_csv('bow_20.csv')\n",
    "bow = pd.concat([bow1, bow2], ignore_index=True)\n",
    "weather_dfs.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_north1 = pd.read_csv('bow_north_18-19.csv')\n",
    "bow_north2 = pd.read_csv('bow_north_20.csv')\n",
    "bow_north = pd.concat([bow_north1, bow_north2], ignore_index=True)\n",
    "weather_dfs.append(bow_north)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "grassy_lake1 = pd.read_csv('grassy_lake_18-19.csv')\n",
    "grassy_lake2 = pd.read_csv('grassy_lake_20.csv')\n",
    "grassy_lake = pd.concat([grassy_lake1, grassy_lake2], ignore_index=True)\n",
    "weather_dfs.append(grassy_lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_names = ['rolling_hills','barnwell','lethbridge','vauxhall','fincastle','bow','bow_north','grassy_lake']\n",
    "for frame in weather_dfs:\n",
    "    index = 0\n",
    "    frame = engineer(frame)\n",
    "    filename = location_names[index]\n",
    "    frame.to_csv(filename + '2_processed.csv')\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 69)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_hills.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>MeanRH</th>\n",
       "      <th>Precip</th>\n",
       "      <th>Wind2</th>\n",
       "      <th>Wind10</th>\n",
       "      <th>Wind10Dir</th>\n",
       "      <th>...</th>\n",
       "      <th>MeanTemp_uDPSum_7</th>\n",
       "      <th>MinTemp_u20Sum_1</th>\n",
       "      <th>MinTemp_u20Sum_3</th>\n",
       "      <th>MinTemp_u20Sum_7</th>\n",
       "      <th>MaxTemp_u20Sum_1</th>\n",
       "      <th>MaxTemp_u20Sum_3</th>\n",
       "      <th>MaxTemp_u20Sum_7</th>\n",
       "      <th>MeanTemp_u20Sum_1</th>\n",
       "      <th>MeanTemp_u20Sum_3</th>\n",
       "      <th>MeanTemp_u20Sum_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rolling Hills AGCM</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>5.6</td>\n",
       "      <td>27.9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.5</td>\n",
       "      <td>68.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rolling Hills AGCM</td>\n",
       "      <td>2018-05-28</td>\n",
       "      <td>9.5</td>\n",
       "      <td>31.6</td>\n",
       "      <td>21.8</td>\n",
       "      <td>44.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>20.1</td>\n",
       "      <td>182.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rolling Hills AGCM</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>11.1</td>\n",
       "      <td>22.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>25.3</td>\n",
       "      <td>341.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rolling Hills AGCM</td>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>7.9</td>\n",
       "      <td>20.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>344.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rolling Hills AGCM</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>4.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>18.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Station       Date  MinTemp  MaxTemp  MeanTemp  MeanRH  Precip  \\\n",
       "0  Rolling Hills AGCM 2018-05-27      5.6     27.9      18.7    57.0     0.0   \n",
       "1  Rolling Hills AGCM 2018-05-28      9.5     31.6      21.8    44.8     0.0   \n",
       "2  Rolling Hills AGCM 2018-05-29     11.1     22.1      17.3    42.3     0.0   \n",
       "3  Rolling Hills AGCM 2018-05-30      7.9     20.4      13.0    65.4     6.1   \n",
       "4  Rolling Hills AGCM 2018-05-31      4.2     10.2       8.5    92.5     5.2   \n",
       "\n",
       "   Wind2  Wind10  Wind10Dir  ...  MeanTemp_uDPSum_7  MinTemp_u20Sum_1  \\\n",
       "0    9.9    11.5       68.1  ...                NaN               NaN   \n",
       "1   16.3    20.1      182.7  ...                NaN               1.0   \n",
       "2   19.9    25.3      341.5  ...                NaN               1.0   \n",
       "3   13.0    15.9      344.6  ...                NaN               1.0   \n",
       "4   14.8    18.2       40.0  ...                NaN               1.0   \n",
       "\n",
       "   MinTemp_u20Sum_3  MinTemp_u20Sum_7  MaxTemp_u20Sum_1  MaxTemp_u20Sum_3  \\\n",
       "0               NaN               NaN               NaN               NaN   \n",
       "1               NaN               NaN               0.0               NaN   \n",
       "2               NaN               NaN               0.0               NaN   \n",
       "3               3.0               NaN               0.0               0.0   \n",
       "4               3.0               NaN               0.0               0.0   \n",
       "\n",
       "   MaxTemp_u20Sum_7  MeanTemp_u20Sum_1  MeanTemp_u20Sum_3  MeanTemp_u20Sum_7  \n",
       "0               NaN                NaN                NaN                NaN  \n",
       "1               NaN                1.0                NaN                NaN  \n",
       "2               NaN                0.0                NaN                NaN  \n",
       "3               NaN                1.0                2.0                NaN  \n",
       "4               NaN                1.0                2.0                NaN  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_hills.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge weather location dfs with main dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling_hills = df2[df2['FieldID'] == 'Vauxhall'].copy()\n",
    "df_barnwell = df2[df2['FieldID'] == 'Cranford'].copy()\n",
    "df_lethbridge = df2[(df2['FieldID'] == '1919') | (df2['FieldID'] == '1920') | (df2['FieldID'] == '1921') | (df2['FieldID'] == '1922') | (df2['FieldID'] == '2042')].copy()\n",
    "df_vauxhall = df2[(df2['FieldID'] == '1906') | (df2['FieldID'] == '1910') | (df2['FieldID'] == '2007')].copy()\n",
    "df_fincastle = df2[df2['FieldID'] == '1904'].copy()\n",
    "df_bow = df2[(df2['FieldID'] == '1917') | (df2['FieldID'] == '2006') | (df2['FieldID'] == '2004') | (df2['FieldID'] == 'Taber')].copy()\n",
    "df_bow_north = df2[df2['FieldID'] == '1915'].copy()\n",
    "df_grassy_lake = df2[df2['FieldID'] == '2001'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 85)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rolling_hills.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FieldID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year_x</th>\n",
       "      <th>JDay</th>\n",
       "      <th>SsCtMean</th>\n",
       "      <th>SsCtSD</th>\n",
       "      <th>SsMean</th>\n",
       "      <th>logSsMean</th>\n",
       "      <th>TtCt</th>\n",
       "      <th>TtSD</th>\n",
       "      <th>...</th>\n",
       "      <th>Year_y</th>\n",
       "      <th>SamplerNo</th>\n",
       "      <th>CropType</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Region</th>\n",
       "      <th>Province</th>\n",
       "      <th>SamplerPresent</th>\n",
       "      <th>SamplerType</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>2018</td>\n",
       "      <td>164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.070242</td>\n",
       "      <td>-112.106166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>2018</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.070242</td>\n",
       "      <td>-112.106166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>2018</td>\n",
       "      <td>166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.070242</td>\n",
       "      <td>-112.106166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-16</td>\n",
       "      <td>2018</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.070242</td>\n",
       "      <td>-112.106166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>2018</td>\n",
       "      <td>168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1.202761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.070242</td>\n",
       "      <td>-112.106166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FieldID       Date  Year_x  JDay SsCtMean  SsCtSD  SsMean  logSsMean  \\\n",
       "905  Vauxhall 2018-06-13    2018   164      NaN     NaN     NaN        NaN   \n",
       "906  Vauxhall 2018-06-14    2018   165      NaN     NaN     NaN        NaN   \n",
       "907  Vauxhall 2018-06-15    2018   166      NaN     NaN     NaN        NaN   \n",
       "908  Vauxhall 2018-06-16    2018   167      NaN     NaN     NaN        NaN   \n",
       "909  Vauxhall 2018-06-17    2018   168      NaN     NaN   14.95   1.202761   \n",
       "\n",
       "     TtCt  TtSD  ...  Year_y  SamplerNo  CropType  Crop    Region  Province  \\\n",
       "905   NaN   NaN  ...  2019.0        NaN      City   NaN  Vauxhall   Alberta   \n",
       "906   NaN   NaN  ...  2019.0        NaN      City   NaN  Vauxhall   Alberta   \n",
       "907   NaN   NaN  ...  2019.0        NaN      City   NaN  Vauxhall   Alberta   \n",
       "908   NaN   NaN  ...  2019.0        NaN      City   NaN  Vauxhall   Alberta   \n",
       "909   NaN   NaN  ...  2019.0        NaN      City   NaN  Vauxhall   Alberta   \n",
       "\n",
       "     SamplerPresent  SamplerType        Lat        Long  \n",
       "905              No          NaN  50.070242 -112.106166  \n",
       "906              No          NaN  50.070242 -112.106166  \n",
       "907              No          NaN  50.070242 -112.106166  \n",
       "908              No          NaN  50.070242 -112.106166  \n",
       "909              No          NaN  50.070242 -112.106166  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rolling_hills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['rolling_hills','barnwell','lethbridge','vauxhall','fincastle','bow','bow_north','grassy_lake']\n",
    "data_dfs = [df_rolling_hills, df_barnwell, df_lethbridge,df_vauxhall, df_fincastle, df_bow, df_bow_north, df_grassy_lake]\n",
    "\n",
    "for i in range(len(data_dfs)):\n",
    "    frame = data_dfs[i]\n",
    "    weather = weather_dfs[i]\n",
    "    frame = frame.merge(weather, how='left', on='Date', copy=False)\n",
    "    data_dfs[i] = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dfs[0] = data_dfs[0].merge(weather_dfs[0], how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 153)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dfs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 85)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rolling_hills.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FieldID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year_x</th>\n",
       "      <th>JDay</th>\n",
       "      <th>SsCtMean</th>\n",
       "      <th>SsCtSD</th>\n",
       "      <th>SsMean</th>\n",
       "      <th>logSsMean</th>\n",
       "      <th>TtCt</th>\n",
       "      <th>TtSD</th>\n",
       "      <th>...</th>\n",
       "      <th>MeanTemp_uDPSum_7</th>\n",
       "      <th>MinTemp_u20Sum_1</th>\n",
       "      <th>MinTemp_u20Sum_3</th>\n",
       "      <th>MinTemp_u20Sum_7</th>\n",
       "      <th>MaxTemp_u20Sum_1</th>\n",
       "      <th>MaxTemp_u20Sum_3</th>\n",
       "      <th>MaxTemp_u20Sum_7</th>\n",
       "      <th>MeanTemp_u20Sum_1</th>\n",
       "      <th>MeanTemp_u20Sum_3</th>\n",
       "      <th>MeanTemp_u20Sum_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>2018</td>\n",
       "      <td>164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>2018</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>2018</td>\n",
       "      <td>166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-16</td>\n",
       "      <td>2018</td>\n",
       "      <td>167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>2018</td>\n",
       "      <td>168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1.202761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FieldID       Date  Year_x  JDay SsCtMean  SsCtSD  SsMean  logSsMean  \\\n",
       "0  Vauxhall 2018-06-13    2018   164      NaN     NaN     NaN        NaN   \n",
       "1  Vauxhall 2018-06-14    2018   165      NaN     NaN     NaN        NaN   \n",
       "2  Vauxhall 2018-06-15    2018   166      NaN     NaN     NaN        NaN   \n",
       "3  Vauxhall 2018-06-16    2018   167      NaN     NaN     NaN        NaN   \n",
       "4  Vauxhall 2018-06-17    2018   168      NaN     NaN   14.95   1.202761   \n",
       "\n",
       "   TtCt  TtSD  ...  MeanTemp_uDPSum_7  MinTemp_u20Sum_1  MinTemp_u20Sum_3  \\\n",
       "0   NaN   NaN  ...                0.0               1.0               3.0   \n",
       "1   NaN   NaN  ...                0.0               1.0               3.0   \n",
       "2   NaN   NaN  ...                0.0               1.0               3.0   \n",
       "3   NaN   NaN  ...                0.0               1.0               3.0   \n",
       "4   NaN   NaN  ...                0.0               1.0               3.0   \n",
       "\n",
       "   MinTemp_u20Sum_7  MaxTemp_u20Sum_1  MaxTemp_u20Sum_3  MaxTemp_u20Sum_7  \\\n",
       "0               7.0               0.0               2.0               2.0   \n",
       "1               7.0               0.0               1.0               2.0   \n",
       "2               7.0               0.0               0.0               2.0   \n",
       "3               7.0               0.0               0.0               2.0   \n",
       "4               7.0               1.0               1.0               3.0   \n",
       "\n",
       "   MeanTemp_u20Sum_1  MeanTemp_u20Sum_3  MeanTemp_u20Sum_7  \n",
       "0                1.0                3.0                6.0  \n",
       "1                1.0                3.0                6.0  \n",
       "2                1.0                3.0                6.0  \n",
       "3                1.0                3.0                7.0  \n",
       "4                1.0                3.0                7.0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rolling_hills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.concat([cran_df2, taber_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 107)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_df = df.loc[(df['Location.x'] == '1915') | (df['Location.x'] == '1917')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 98)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl['Date (Local Standard Time)'] = pd.to_datetime(gl['Date (Local Standard Time)'])\n",
    "\n",
    "gl_df2 = gl_df.merge(gl, how='left', left_on='Date', right_on='Date (Local Standard Time)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 107)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.concat([main, gl_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 107)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_df = df.loc[(df['Location.x'] == '1906') | (df['Location.x'] == '1910') | (df['Location.x'] == 'Vauxhall')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 98)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaux['Date (Local Standard Time)'] = pd.to_datetime(vaux['Date (Local Standard Time)'])\n",
    "\n",
    "v_df2 = v_df.merge(vaux, how='left', left_on='Date', right_on='Date (Local Standard Time)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 107)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.concat([main, v_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 107)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = df.loc[df['Location.x'] == '1919']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 98)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "nine['Date (Local Standard Time)'] = pd.to_datetime(nine['Date (Local Standard Time)'])\n",
    "\n",
    "n_df2 = n_df.merge(nine, how='left', left_on='Date', right_on='Date (Local Standard Time)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 107)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.concat([main, n_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568, 107)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568, 98)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.to_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location.x</th>\n",
       "      <th>JDay</th>\n",
       "      <th>Date</th>\n",
       "      <th>SsCtMean</th>\n",
       "      <th>SsCtSD</th>\n",
       "      <th>SsMean</th>\n",
       "      <th>logSsMean</th>\n",
       "      <th>SsSD</th>\n",
       "      <th>SsClean</th>\n",
       "      <th>logSsClean</th>\n",
       "      <th>...</th>\n",
       "      <th>Long</th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Date (Local Standard Time)</th>\n",
       "      <th>Air Temp. Min. (�C)</th>\n",
       "      <th>Air Temp. Max. (�C)</th>\n",
       "      <th>Air Temp. Avg. (�C)</th>\n",
       "      <th>Humidity Avg. (%)</th>\n",
       "      <th>Precip. (mm)</th>\n",
       "      <th>Wind Speed 10 m Avg. (km/h)</th>\n",
       "      <th>Frost Probability 0�C (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cranford</td>\n",
       "      <td>164</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295.035</td>\n",
       "      <td>2.471343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barnwell AGDM</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cranford</td>\n",
       "      <td>165</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.900</td>\n",
       "      <td>2.033021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barnwell AGDM</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>4.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>65.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cranford</td>\n",
       "      <td>166</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.775</td>\n",
       "      <td>2.219519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barnwell AGDM</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>7.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>77.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cranford</td>\n",
       "      <td>167</td>\n",
       "      <td>2018-06-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.380</td>\n",
       "      <td>2.144200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barnwell AGDM</td>\n",
       "      <td>2018-06-16</td>\n",
       "      <td>11.2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>89.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cranford</td>\n",
       "      <td>168</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.545</td>\n",
       "      <td>2.191856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barnwell AGDM</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>7.7</td>\n",
       "      <td>21.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location.x  JDay       Date  SsCtMean  SsCtSD   SsMean  logSsMean  SsSD  \\\n",
       "0   Cranford   164 2018-06-13       NaN     NaN  295.035   2.471343   NaN   \n",
       "1   Cranford   165 2018-06-14       NaN     NaN  106.900   2.033021   NaN   \n",
       "2   Cranford   166 2018-06-15       NaN     NaN  164.775   2.219519   NaN   \n",
       "3   Cranford   167 2018-06-16       NaN     NaN  138.380   2.144200   NaN   \n",
       "4   Cranford   168 2018-06-17       NaN     NaN  154.545   2.191856   NaN   \n",
       "\n",
       "   SsClean  logSsClean  ...  Long   Station Name Date (Local Standard Time)  \\\n",
       "0      NaN         NaN  ...   NaN  Barnwell AGDM                 2018-06-13   \n",
       "1      NaN         NaN  ...   NaN  Barnwell AGDM                 2018-06-14   \n",
       "2      NaN         NaN  ...   NaN  Barnwell AGDM                 2018-06-15   \n",
       "3      NaN         NaN  ...   NaN  Barnwell AGDM                 2018-06-16   \n",
       "4      NaN         NaN  ...   NaN  Barnwell AGDM                 2018-06-17   \n",
       "\n",
       "   Air Temp. Min. (�C)  Air Temp. Max. (�C)  Air Temp. Avg. (�C)  \\\n",
       "0                  7.7                 26.5                 17.9   \n",
       "1                  4.6                 22.0                 13.1   \n",
       "2                  7.2                 22.0                 13.2   \n",
       "3                 11.2                 18.1                 12.5   \n",
       "4                  7.7                 21.8                 15.8   \n",
       "\n",
       "   Humidity Avg. (%)  Precip. (mm)  Wind Speed 10 m Avg. (km/h)  \\\n",
       "0               38.4           0.0                         22.6   \n",
       "1               65.9           1.2                         19.1   \n",
       "2               77.8           7.2                         11.1   \n",
       "3               89.3           9.8                         16.5   \n",
       "4               67.1           0.0                          7.8   \n",
       "\n",
       "   Frost Probability 0�C (%)  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SamplerNo        568\n",
       "DiffMinSoilT     333\n",
       "DiffMeanSoilT    333\n",
       "DiffMaxSoilT     333\n",
       "MaxSoilT_1d      331\n",
       "MinSoilT_1d      331\n",
       "MeanSoilT_1d     331\n",
       "MaxSoilTemp      327\n",
       "MeanSoilTemp     327\n",
       "MinSoilTemp      327\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Location.x', 'JDay', 'Date', 'SsCtMean', 'SsCtSD', 'SsMean',\n",
       "       'logSsMean', 'SsSD', 'SsClean', 'logSsClean',\n",
       "       ...\n",
       "       'Long', 'Station Name', 'Date (Local Standard Time)',\n",
       "       'Air Temp. Min. (�C)', 'Air Temp. Max. (�C)', 'Air Temp. Avg. (�C)',\n",
       "       'Humidity Avg. (%)', 'Precip. (mm)', 'Wind Speed 10 m Avg. (km/h)',\n",
       "       'Frost Probability 0�C (%)'],\n",
       "      dtype='object', length=107)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Location.x', 'JDay', 'Date', 'SsCtMean', 'SsCtSD', 'SsMean',\n",
       "       'logSsMean', 'SsSD', 'SsClean', 'logSsClean', 'TtCt', 'TtSD', 'Water.',\n",
       "       'logSsMean_t1', 'Year_x', 'MeanWetness', 'DiffMeanWet', 'MeanWet_1d',\n",
       "       'MaxWetness', 'DiffMaxWet', 'MaxWet_1d', 'MinWetness', 'DiffMinWet',\n",
       "       'MinWet_1d', 'MeanTemp', 'DiffMeanT', 'MeanT_1d', 'MaxTemp', 'DiffMaxT',\n",
       "       'MaxT_1d', 'MinTemp', 'DiffMinT', 'MinT_1d', 'MeanRH', 'DiffMeanRH',\n",
       "       'MeanRH_1d', 'MaxRH', 'DiffMaxRH', 'MaxRH_1d', 'MinRH', 'DiffMinRH',\n",
       "       'MinRH_1d', 'DiffRH_0d', 'DiffRH_1d', 'DiffRH_2d', 'MaxDiffRH_2h',\n",
       "       'MaxDiffRH_3h', 'MeanVPD', 'DiffMeanVPD', 'MeanVPD_1d', 'MaxVPD',\n",
       "       'DiffMaxVPD', 'MaxVPD_1d', 'MinVPD', 'DiffMinVPD', 'TotalPrecip',\n",
       "       'Precip_1d', 'RainYN', 'MaxRain', 'MinRain', 'MeanWC', 'DiffMeanWC',\n",
       "       'MeanWC_1d', 'MaxWC', 'DiffMaxWC', 'MaxWC_1d', 'MinWC', 'DiffMinWC',\n",
       "       'MinWC_1d', 'MeanDP', 'DiffMeanDP', 'MeanDP_1d', 'MaxDP', 'DiffMaxDP',\n",
       "       'MaxDP_1d', 'MinDP', 'DiffMinDP', 'MinDP_1d', 'MeanSoilTemp',\n",
       "       'DiffMeanSoilT', 'MeanSoilT_1d', 'MaxSoilTemp', 'DiffMaxSoilT',\n",
       "       'MaxSoilT_1d', 'MinSoilTemp', 'DiffMinSoilT', 'MinSoilT_1d', 'Year_y',\n",
       "       'FieldID', 'SamplerNo', 'CropType', 'Crop', 'Region', 'Province',\n",
       "       'SamplerPresent', 'SamplerType', 'Lat', 'Long'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['SamplerNo', 'Date (Local Standard Time)', 'Station Name', 'SamplerPresent','SamplerType','Province','Region','Crop','CropType','FieldID']\n",
    "\n",
    "main.drop(labels=to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568, 97)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.to_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighthouse",
   "language": "python",
   "name": "lighthouse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
