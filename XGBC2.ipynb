{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jon's weather data (instead of Alberta provincial)\n",
    "df = pd.read_csv('JFE_data_18-19.csv', index_col=0)\n",
    "\n",
    "# sort by date\n",
    "df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# make date the index\n",
    "df.set_index('Date',inplace=True)\n",
    "\n",
    "#to_drop = ['AvgTemp_7','AvgRH_7', 'AvgDP_7','Precip_7', 'MaxTemp_7',\n",
    " #      'MinTemp_7','SsMean_7']\n",
    "#df.drop(labels=to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['SsMean'] < 250].SsMean.count())\n",
    "print(df.loc[df['SsMean'] > 250].SsMean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target\n",
    "# 0 = less than 250\n",
    "# 1 = over 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat(data):\n",
    "    if data < 250:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['SsMean'].apply(create_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC, no scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off end of 2019 as test set\n",
    "test_size = df.shape[0] - 14\n",
    "train, test = df.iloc[:test_size], df.iloc[test_size:]\n",
    "\n",
    "X_train, X_test = train.drop(labels=['SsMean','logSsMean', 'label'], axis=1), test.drop(labels=['SsMean','logSsMean','label'], axis=1)\n",
    "y_train, y_test = train.label, test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(labels=['SsMean','logSsMean', 'label'], axis=1)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Location'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Location'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-d060a4a4c6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Location'"
     ]
    }
   ],
   "source": [
    "# encode location\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train['Location'])\n",
    "X_train['Location'] = le.transform(X_train['Location'])\n",
    "X_test['Location'] = le.transform(X_test['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reneehall/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:34:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xg = xgb.XGBClassifier()\n",
    "xg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8131868131868132\n",
      "Train auc: 1.0\n",
      "Test auc: 0.8472222222222223\n",
      "Train precision: 1.0\n",
      "Test precision: 0.6666666666666666\n",
      "Train recall: 1.0\n",
      "Test recall: 0.7407407407407407\n",
      "F1 score train: 1.0\n",
      "F1 score test: 0.7017543859649122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86        64\n",
      "           1       0.67      0.74      0.70        27\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.78      0.79      0.78        91\n",
      "weighted avg       0.82      0.81      0.82        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = xg.predict(X_test)\n",
    "y_train_pred = xg.predict(X_train)\n",
    "\n",
    "test_acc = xg.score(X_test, y_test)\n",
    "train_acc = xg.score(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "train_probs = xg.predict_proba(X_train)[:,1]\n",
    "train_auc = roc_auc_score(y_train,train_probs)\n",
    "print('Train auc:', train_auc)\n",
    "test_probs = xg.predict_proba(X_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test,test_probs)\n",
    "print('Test auc:', test_auc)\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "print('Train precision:', train_precision)\n",
    "print('Test precision:', test_precision)\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "print('Train recall:', train_recall)\n",
    "print('Test recall:', test_recall)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score train:', train_f1)\n",
    "print('F1 score test:', test_f1)\n",
    "\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fe2f8a1f580>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(xg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC with scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off end of 2019 as test set\n",
    "test_size = df.shape[0] - 14\n",
    "train, test = df.iloc[:test_size], df.iloc[test_size:]\n",
    "\n",
    "X_train, X_test = train.drop(labels=['SsMean','logSsMean', 'label'], axis=1), test.drop(labels=['SsMean','logSsMean','label'], axis=1)\n",
    "y_train, y_test = train.label, test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(labels=['SsMean','logSsMean', 'label'], axis=1)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-106-a169bd59956c>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Location'] = le.transform(X_train['Location'])\n",
      "<ipython-input-106-a169bd59956c>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Location'] = le.transform(X_test['Location'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# encode location\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train['Location'])\n",
    "X_train['Location'] = le.transform(X_train['Location'])\n",
    "X_test['Location'] = le.transform(X_test['Location'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reneehall/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier()\n",
    "xg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.7692307692307693\n",
      "Train auc: 1.0\n",
      "Test auc: 0.8463463463463463\n",
      "Train precision: 1.0\n",
      "Test precision: 0.6739130434782609\n",
      "Train recall: 1.0\n",
      "Test recall: 0.8378378378378378\n",
      "F1 score train: 1.0\n",
      "F1 score test: 0.746987951807229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79        54\n",
      "           1       0.67      0.84      0.75        37\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.78      0.77        91\n",
      "weighted avg       0.79      0.77      0.77        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xg.predict(X_test)\n",
    "y_train_pred = xg.predict(X_train)\n",
    "\n",
    "test_acc = xg.score(X_test, y_test)\n",
    "train_acc = xg.score(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "train_probs = xg.predict_proba(X_train)[:,1]\n",
    "train_auc = roc_auc_score(y_train,train_probs)\n",
    "print('Train auc:', train_auc)\n",
    "test_probs = xg.predict_proba(X_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test,test_probs)\n",
    "print('Test auc:', test_auc)\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "print('Train precision:', train_precision)\n",
    "print('Test precision:', test_precision)\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "print('Train recall:', train_recall)\n",
    "print('Test recall:', test_recall)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score train:', train_f1)\n",
    "print('F1 score test:', test_f1)\n",
    "\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fe2f983d9a0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(xg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 500+ label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['SsMean'] < 500].SsMean.count())\n",
    "print(df.loc[df['SsMean'] > 500].SsMean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target\n",
    "# 0 = less than 500\n",
    "# 1 = over 500\n",
    "\n",
    "def create_500(data):\n",
    "    if data < 500:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['SsMean'].apply(create_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create balanced dataset\n",
    "class_0 = df.loc[df['label']==0]\n",
    "class_1 = df.loc[df['label']==1]\n",
    "\n",
    "class_1_sample = class_1.sample(n=377, replace=True)\n",
    "\n",
    "bdf = pd.concat([class_0, class_1_sample], axis=0)\n",
    "bdf.sort_values(by='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 61)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC, scaling, 500+ label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off end of 2019 as test set\n",
    "test_size = bdf.shape[0] - 14\n",
    "train, test = bdf.iloc[:test_size], bdf.iloc[test_size:]\n",
    "\n",
    "X_train, X_test = train.drop(labels=['SsMean','logSsMean', 'label'], axis=1), test.drop(labels=['SsMean','logSsMean','label'], axis=1)\n",
    "y_train, y_test = train.label, test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bdf.drop(labels=['SsMean','logSsMean', 'label'], axis=1)\n",
    "y = bdf.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-132-86dd1da13430>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Location'] = le.transform(X_train['Location'])\n",
      "<ipython-input-132-86dd1da13430>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Location'] = le.transform(X_test['Location'])\n",
      "/Users/reneehall/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:39:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode location\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train['Location'])\n",
    "X_train['Location'] = le.transform(X_train['Location'])\n",
    "X_test['Location'] = le.transform(X_test['Location'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "xg = xgb.XGBClassifier()\n",
    "xg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8785714285714286\n",
      "Train auc: 1.0\n",
      "Test auc: 0.9756695972193824\n",
      "Train precision: 1.0\n",
      "Test precision: 0.8255813953488372\n",
      "Train recall: 1.0\n",
      "Test recall: 0.9726027397260274\n",
      "F1 score train: 1.0\n",
      "F1 score test: 0.8930817610062893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86        67\n",
      "           1       0.83      0.97      0.89        73\n",
      "\n",
      "    accuracy                           0.88       140\n",
      "   macro avg       0.89      0.87      0.88       140\n",
      "weighted avg       0.89      0.88      0.88       140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fe2fa203880>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = xg.predict(X_test)\n",
    "y_train_pred = xg.predict(X_train)\n",
    "\n",
    "test_acc = xg.score(X_test, y_test)\n",
    "train_acc = xg.score(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "train_probs = xg.predict_proba(X_train)[:,1]\n",
    "train_auc = roc_auc_score(y_train,train_probs)\n",
    "print('Train auc:', train_auc)\n",
    "test_probs = xg.predict_proba(X_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test,test_probs)\n",
    "print('Test auc:', test_auc)\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "print('Train precision:', train_precision)\n",
    "print('Test precision:', test_precision)\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "print('Train recall:', train_recall)\n",
    "print('Test recall:', test_recall)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score train:', train_f1)\n",
    "print('F1 score test:', test_f1)\n",
    "\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)\n",
    "\n",
    "plot_confusion_matrix(xg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC, no scaling, 500+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off end of 2019 as test set\n",
    "test_size = bdf.shape[0] - 14\n",
    "train, test = bdf.iloc[:test_size], bdf.iloc[test_size:]\n",
    "\n",
    "X_train, X_test = train.drop(labels=['SsMean','logSsMean', 'label'], axis=1), test.drop(labels=['SsMean','logSsMean','label'], axis=1)\n",
    "y_train, y_test = train.label, test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bdf.drop(labels=['SsMean','logSsMean', 'label'], axis=1)\n",
    "y = bdf.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-136-1d60d416afa3>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Location'] = le.transform(X_train['Location'])\n",
      "<ipython-input-136-1d60d416afa3>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Location'] = le.transform(X_test['Location'])\n",
      "/Users/reneehall/opt/anaconda3/envs/lighthouse/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode location\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train['Location'])\n",
    "X_train['Location'] = le.transform(X_train['Location'])\n",
    "X_test['Location'] = le.transform(X_test['Location'])\n",
    "\n",
    "xg = xgb.XGBClassifier()\n",
    "xg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8785714285714286\n",
      "Train auc: 1.0\n",
      "Test auc: 0.9756695972193824\n",
      "Train precision: 1.0\n",
      "Test precision: 0.8255813953488372\n",
      "Train recall: 1.0\n",
      "Test recall: 0.9726027397260274\n",
      "F1 score train: 1.0\n",
      "F1 score test: 0.8930817610062893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86        67\n",
      "           1       0.83      0.97      0.89        73\n",
      "\n",
      "    accuracy                           0.88       140\n",
      "   macro avg       0.89      0.87      0.88       140\n",
      "weighted avg       0.89      0.88      0.88       140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fe2f8be07c0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = xg.predict(X_test)\n",
    "y_train_pred = xg.predict(X_train)\n",
    "\n",
    "test_acc = xg.score(X_test, y_test)\n",
    "train_acc = xg.score(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "train_probs = xg.predict_proba(X_train)[:,1]\n",
    "train_auc = roc_auc_score(y_train,train_probs)\n",
    "print('Train auc:', train_auc)\n",
    "test_probs = xg.predict_proba(X_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test,test_probs)\n",
    "print('Test auc:', test_auc)\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "print('Train precision:', train_precision)\n",
    "print('Test precision:', test_precision)\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "print('Train recall:', train_recall)\n",
    "print('Test recall:', test_recall)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score train:', train_f1)\n",
    "print('F1 score test:', test_f1)\n",
    "\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)\n",
    "\n",
    "plot_confusion_matrix(xg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = pd.DataFrame(test)\n",
    "r_df['pred'] = y_pred\n",
    "r_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = r_df[r_df['label'] != r_df['pred']]\n",
    "correct = r_df[r_df['label'] == r_df['pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_df = pd.DataFrame()\n",
    "for i in incorrect.index.tolist():\n",
    "    wrong_df = wrong_df.append(test.iloc[i])\n",
    "    \n",
    "right_df = pd.DataFrame()\n",
    "for i in correct.index.tolist():\n",
    "    right_df = right_df.append(test.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AvgDP', 'AvgDP_1', 'AvgDP_3', 'AvgDP_7', 'AvgRH', 'AvgRH_1', 'AvgRH_3',\n",
       "       'AvgRH_7', 'AvgTemp', 'AvgTemp_1', 'AvgTemp_3', 'AvgTemp_7',\n",
       "       'AvgWindSpeed', 'Date', 'JDay', 'Location', 'MaxTemp', 'MaxTemp_1',\n",
       "       'MaxTemp_3', 'MaxTemp_7', 'MinTemp', 'MinTemp_1', 'MinTemp_3',\n",
       "       'MinTemp_7', 'Precip', 'Precip_1', 'Precip_3', 'Precip_7', 'SsMean',\n",
       "       'SsMean_1', 'SsMean_3', 'SsMean_7', 'YearWeek', 'label', 'logSsMean',\n",
       "       'month', 'precip_3dTotal', 'pred', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgDP_1</th>\n",
       "      <th>AvgDP_3</th>\n",
       "      <th>AvgDP_7</th>\n",
       "      <th>AvgRH_1</th>\n",
       "      <th>AvgRH_3</th>\n",
       "      <th>AvgRH_7</th>\n",
       "      <th>AvgTemp_1</th>\n",
       "      <th>AvgTemp_3</th>\n",
       "      <th>AvgTemp_7</th>\n",
       "      <th>Location</th>\n",
       "      <th>...</th>\n",
       "      <th>MaxTemp_7</th>\n",
       "      <th>MinTemp_1</th>\n",
       "      <th>MinTemp_3</th>\n",
       "      <th>MinTemp_7</th>\n",
       "      <th>Precip_3</th>\n",
       "      <th>Precip_7</th>\n",
       "      <th>SsMean</th>\n",
       "      <th>SsMean_1</th>\n",
       "      <th>SsMean_3</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.10</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>10.282857</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.628571</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>17.757143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.542857</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.266667</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>2379.4</td>\n",
       "      <td>2362.23</td>\n",
       "      <td>863.873333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.88</td>\n",
       "      <td>11.046667</td>\n",
       "      <td>10.605714</td>\n",
       "      <td>83.9</td>\n",
       "      <td>70.733333</td>\n",
       "      <td>64.242857</td>\n",
       "      <td>13.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>17.757143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.528571</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>768.5</td>\n",
       "      <td>2379.40</td>\n",
       "      <td>1629.076667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.88</td>\n",
       "      <td>11.046667</td>\n",
       "      <td>10.605714</td>\n",
       "      <td>83.9</td>\n",
       "      <td>70.733333</td>\n",
       "      <td>64.242857</td>\n",
       "      <td>13.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>17.757143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.528571</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>768.5</td>\n",
       "      <td>2379.40</td>\n",
       "      <td>1629.076667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AvgDP_1    AvgDP_3    AvgDP_7  AvgRH_1    AvgRH_3    AvgRH_7  AvgTemp_1  \\\n",
       "8     11.10  11.800000  10.282857     56.0  58.500000  62.628571       19.9   \n",
       "17     9.88  11.046667  10.605714     83.9  70.733333  64.242857       13.1   \n",
       "20     9.88  11.046667  10.605714     83.9  70.733333  64.242857       13.1   \n",
       "\n",
       "    AvgTemp_3  AvgTemp_7  Location  ...  MaxTemp_7  MinTemp_1  MinTemp_3  \\\n",
       "8        20.1  17.757143       2.0  ...  26.542857       12.9  12.266667   \n",
       "17       16.9  17.757143       2.0  ...  26.528571        7.7  10.366667   \n",
       "20       16.9  17.757143       2.0  ...  26.528571        7.7  10.366667   \n",
       "\n",
       "    MinTemp_7  Precip_3  Precip_7  SsMean  SsMean_1     SsMean_3  pred  \n",
       "8    9.700000  0.866667  0.657143  2379.4   2362.23   863.873333   0.0  \n",
       "17   9.571429  0.866667  0.800000   768.5   2379.40  1629.076667   0.0  \n",
       "20   9.571429  0.866667  0.800000   768.5   2379.40  1629.076667   0.0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['AvgDP_1', 'AvgDP_3', 'AvgDP_7', 'AvgRH_1', 'AvgRH_3',\n",
    "       'AvgRH_7', 'AvgTemp_1', 'AvgTemp_3', 'AvgTemp_7',\n",
    "       'Location', 'MaxTemp_1',\n",
    "       'MaxTemp_3', 'MaxTemp_7', 'MinTemp_1', 'MinTemp_3',\n",
    "       'MinTemp_7', 'Precip_3', 'Precip_7', 'SsMean',\n",
    "       'SsMean_1', 'SsMean_3',\n",
    "       'pred']\n",
    "\n",
    "wrong_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgDP_1</th>\n",
       "      <th>AvgDP_3</th>\n",
       "      <th>AvgDP_7</th>\n",
       "      <th>AvgRH_1</th>\n",
       "      <th>AvgRH_3</th>\n",
       "      <th>AvgRH_7</th>\n",
       "      <th>AvgTemp_1</th>\n",
       "      <th>AvgTemp_3</th>\n",
       "      <th>AvgTemp_7</th>\n",
       "      <th>Location</th>\n",
       "      <th>...</th>\n",
       "      <th>MaxTemp_7</th>\n",
       "      <th>MinTemp_1</th>\n",
       "      <th>MinTemp_3</th>\n",
       "      <th>MinTemp_7</th>\n",
       "      <th>Precip_3</th>\n",
       "      <th>Precip_7</th>\n",
       "      <th>SsMean</th>\n",
       "      <th>SsMean_1</th>\n",
       "      <th>SsMean_3</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.40</td>\n",
       "      <td>12.226667</td>\n",
       "      <td>10.377143</td>\n",
       "      <td>72.5</td>\n",
       "      <td>64.300000</td>\n",
       "      <td>66.885714</td>\n",
       "      <td>16.9</td>\n",
       "      <td>19.366667</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>10.371429</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>2260.510</td>\n",
       "      <td>135.420</td>\n",
       "      <td>595.573333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>11.211429</td>\n",
       "      <td>67.4</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>63.985714</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.266667</td>\n",
       "      <td>18.414286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.628571</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.042857</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>936.380</td>\n",
       "      <td>132.570</td>\n",
       "      <td>1058.526667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.40</td>\n",
       "      <td>12.226667</td>\n",
       "      <td>10.377143</td>\n",
       "      <td>72.5</td>\n",
       "      <td>64.300000</td>\n",
       "      <td>66.885714</td>\n",
       "      <td>16.9</td>\n",
       "      <td>19.366667</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>10.371429</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>2260.510</td>\n",
       "      <td>135.420</td>\n",
       "      <td>595.573333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>11.211429</td>\n",
       "      <td>67.4</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>63.985714</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.266667</td>\n",
       "      <td>18.414286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.628571</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.042857</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>936.380</td>\n",
       "      <td>132.570</td>\n",
       "      <td>1058.526667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.40</td>\n",
       "      <td>12.226667</td>\n",
       "      <td>10.342857</td>\n",
       "      <td>72.5</td>\n",
       "      <td>64.300000</td>\n",
       "      <td>63.714286</td>\n",
       "      <td>16.9</td>\n",
       "      <td>19.366667</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.157143</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>10.071429</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>16864.435</td>\n",
       "      <td>249.440</td>\n",
       "      <td>259.771667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.16</td>\n",
       "      <td>12.620000</td>\n",
       "      <td>10.634286</td>\n",
       "      <td>72.3</td>\n",
       "      <td>64.600000</td>\n",
       "      <td>65.242857</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>17.585714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.771429</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.266667</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>1472.790</td>\n",
       "      <td>308.880</td>\n",
       "      <td>571.583333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.18</td>\n",
       "      <td>12.440000</td>\n",
       "      <td>11.917143</td>\n",
       "      <td>71.4</td>\n",
       "      <td>62.533333</td>\n",
       "      <td>68.800000</td>\n",
       "      <td>17.9</td>\n",
       "      <td>19.933333</td>\n",
       "      <td>18.157143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.871429</td>\n",
       "      <td>11.1</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>11.857143</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>389.480</td>\n",
       "      <td>34.300</td>\n",
       "      <td>53.850000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>11.211429</td>\n",
       "      <td>67.4</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>63.985714</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.266667</td>\n",
       "      <td>18.414286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.628571</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.042857</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>936.380</td>\n",
       "      <td>132.570</td>\n",
       "      <td>1058.526667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.72</td>\n",
       "      <td>12.426667</td>\n",
       "      <td>11.608571</td>\n",
       "      <td>45.6</td>\n",
       "      <td>63.300000</td>\n",
       "      <td>59.757143</td>\n",
       "      <td>21.6</td>\n",
       "      <td>19.766667</td>\n",
       "      <td>19.657143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.814286</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>10.871429</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>84.000</td>\n",
       "      <td>936.380</td>\n",
       "      <td>384.130000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.92</td>\n",
       "      <td>12.206667</td>\n",
       "      <td>11.682857</td>\n",
       "      <td>53.6</td>\n",
       "      <td>67.033333</td>\n",
       "      <td>63.985714</td>\n",
       "      <td>20.2</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>18.885714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.114286</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>11.842857</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>26.930</td>\n",
       "      <td>389.480</td>\n",
       "      <td>145.020000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.10</td>\n",
       "      <td>12.273333</td>\n",
       "      <td>11.131429</td>\n",
       "      <td>56.0</td>\n",
       "      <td>67.533333</td>\n",
       "      <td>62.871429</td>\n",
       "      <td>19.9</td>\n",
       "      <td>18.766667</td>\n",
       "      <td>18.557143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.028571</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>10.314286</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>294.060</td>\n",
       "      <td>1472.790</td>\n",
       "      <td>664.543333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.06</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.825714</td>\n",
       "      <td>57.8</td>\n",
       "      <td>68.833333</td>\n",
       "      <td>61.485714</td>\n",
       "      <td>19.5</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>18.528571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.371429</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>10.414286</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>16864.435</td>\n",
       "      <td>5707.848333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.06</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.825714</td>\n",
       "      <td>57.8</td>\n",
       "      <td>68.833333</td>\n",
       "      <td>61.485714</td>\n",
       "      <td>19.5</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>18.528571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.371429</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>10.414286</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>16864.435</td>\n",
       "      <td>5707.848333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.06</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.574286</td>\n",
       "      <td>57.8</td>\n",
       "      <td>68.833333</td>\n",
       "      <td>63.585714</td>\n",
       "      <td>19.5</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>17.857143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.242857</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>10.428571</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>239.920</td>\n",
       "      <td>2260.510</td>\n",
       "      <td>895.566667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1377.310</td>\n",
       "      <td>239.920</td>\n",
       "      <td>878.616667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1377.310</td>\n",
       "      <td>239.920</td>\n",
       "      <td>878.616667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>1377.310</td>\n",
       "      <td>239.920</td>\n",
       "      <td>878.616667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>2054.905</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>6198.995000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.40</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>11.342857</td>\n",
       "      <td>80.5</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>64.357143</td>\n",
       "      <td>13.3</td>\n",
       "      <td>17.133333</td>\n",
       "      <td>18.471429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.485714</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>9.180</td>\n",
       "      <td>26.930</td>\n",
       "      <td>150.236667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.44</td>\n",
       "      <td>10.846667</td>\n",
       "      <td>11.551429</td>\n",
       "      <td>79.7</td>\n",
       "      <td>64.233333</td>\n",
       "      <td>63.971429</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.757143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>10.514286</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>89.860</td>\n",
       "      <td>84.000</td>\n",
       "      <td>384.316667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>2054.905</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>6198.995000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.04</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.768571</td>\n",
       "      <td>76.7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.057143</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>17.957143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.257143</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.242857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>2054.905</td>\n",
       "      <td>1483.110</td>\n",
       "      <td>6198.995000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.68</td>\n",
       "      <td>9.553333</td>\n",
       "      <td>10.351429</td>\n",
       "      <td>73.4</td>\n",
       "      <td>71.100000</td>\n",
       "      <td>65.900000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>17.171429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.414286</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>9.685714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>44.370</td>\n",
       "      <td>768.500</td>\n",
       "      <td>1836.710000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.32</td>\n",
       "      <td>9.160000</td>\n",
       "      <td>11.248571</td>\n",
       "      <td>70.1</td>\n",
       "      <td>65.133333</td>\n",
       "      <td>64.957143</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.133333</td>\n",
       "      <td>18.257143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.628571</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.766667</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>25.660</td>\n",
       "      <td>89.860</td>\n",
       "      <td>370.080000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.26</td>\n",
       "      <td>9.193333</td>\n",
       "      <td>10.737143</td>\n",
       "      <td>70.8</td>\n",
       "      <td>68.300000</td>\n",
       "      <td>64.257143</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15.533333</td>\n",
       "      <td>17.885714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.414286</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>10.814286</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>49.650</td>\n",
       "      <td>9.180</td>\n",
       "      <td>141.863333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.68</td>\n",
       "      <td>9.553333</td>\n",
       "      <td>10.974286</td>\n",
       "      <td>73.4</td>\n",
       "      <td>71.100000</td>\n",
       "      <td>66.942857</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>17.585714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.271429</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>10.342857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>24.620</td>\n",
       "      <td>2292.600</td>\n",
       "      <td>1353.150000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.10</td>\n",
       "      <td>7.953333</td>\n",
       "      <td>10.654286</td>\n",
       "      <td>58.5</td>\n",
       "      <td>69.433333</td>\n",
       "      <td>64.271429</td>\n",
       "      <td>15.4</td>\n",
       "      <td>14.066667</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.214286</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.533333</td>\n",
       "      <td>9.957143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>15.870</td>\n",
       "      <td>25.660</td>\n",
       "      <td>66.506667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AvgDP_1    AvgDP_3    AvgDP_7  AvgRH_1    AvgRH_3    AvgRH_7  AvgTemp_1  \\\n",
       "0     11.40  12.226667  10.377143     72.5  64.300000  66.885714       16.9   \n",
       "1     12.38  13.333333  11.211429     67.4  65.333333  63.985714       18.9   \n",
       "2     11.40  12.226667  10.377143     72.5  64.300000  66.885714       16.9   \n",
       "3     12.38  13.333333  11.211429     67.4  65.333333  63.985714       18.9   \n",
       "4     11.40  12.226667  10.342857     72.5  64.300000  63.714286       16.9   \n",
       "5     12.16  12.620000  10.634286     72.3  64.600000  65.242857       17.7   \n",
       "6     12.18  12.440000  11.917143     71.4  62.533333  68.800000       17.9   \n",
       "7     12.38  13.333333  11.211429     67.4  65.333333  63.985714       18.9   \n",
       "9     10.72  12.426667  11.608571     45.6  63.300000  59.757143       21.6   \n",
       "10    10.92  12.206667  11.682857     53.6  67.033333  63.985714       20.2   \n",
       "11    11.10  12.273333  11.131429     56.0  67.533333  62.871429       19.9   \n",
       "12    11.06  11.966667  10.825714     57.8  68.833333  61.485714       19.5   \n",
       "13    11.06  11.966667  10.825714     57.8  68.833333  61.485714       19.5   \n",
       "14    11.06  11.966667  10.574286     57.8  68.833333  63.585714       19.5   \n",
       "15     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "16     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "18     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "19     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "21     9.40  10.833333  11.342857     80.5  68.500000  64.357143       13.3   \n",
       "22     9.44  10.846667  11.551429     79.7  64.233333  63.971429       13.5   \n",
       "23     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "24     9.04  10.500000  10.768571     76.7  69.000000  64.057143       13.7   \n",
       "25     7.68   9.553333  10.351429     73.4  71.100000  65.900000       13.0   \n",
       "26     7.32   9.160000  11.248571     70.1  65.133333  64.957143       13.3   \n",
       "27     7.26   9.193333  10.737143     70.8  68.300000  64.257143       13.1   \n",
       "28     7.68   9.553333  10.974286     73.4  71.100000  66.942857       13.0   \n",
       "29     7.10   7.953333  10.654286     58.5  69.433333  64.271429       15.4   \n",
       "\n",
       "    AvgTemp_3  AvgTemp_7  Location  ...  MaxTemp_7  MinTemp_1  MinTemp_3  \\\n",
       "0   19.366667  17.000000       4.0  ...  24.800000        8.7  12.066667   \n",
       "1   20.266667  18.414286       5.0  ...  26.628571        9.4  11.966667   \n",
       "2   19.366667  17.000000       4.0  ...  24.800000        8.7  12.066667   \n",
       "3   20.266667  18.414286       5.0  ...  26.628571        9.4  11.966667   \n",
       "4   19.366667  17.600000       3.0  ...  26.157143        8.7  12.066667   \n",
       "5   19.700000  17.585714       1.0  ...  25.771429       10.5  12.266667   \n",
       "6   19.933333  18.157143       0.0  ...  25.871429       11.1  12.833333   \n",
       "7   20.266667  18.414286       5.0  ...  26.628571        9.4  11.966667   \n",
       "9   19.766667  19.657143       5.0  ...  27.814286       14.2  12.766667   \n",
       "10  18.800000  18.885714       0.0  ...  27.114286       12.9  12.533333   \n",
       "11  18.766667  18.557143       1.0  ...  27.028571       12.9  12.100000   \n",
       "12  18.200000  18.528571       3.0  ...  27.371429       11.3  11.166667   \n",
       "13  18.200000  18.528571       3.0  ...  27.371429       11.3  11.166667   \n",
       "14  18.200000  17.857143       4.0  ...  26.242857       11.3  11.166667   \n",
       "15  16.700000  17.957143       4.0  ...  26.257143        7.6   9.200000   \n",
       "16  16.700000  17.957143       4.0  ...  26.257143        7.6   9.200000   \n",
       "18  16.700000  17.957143       4.0  ...  26.257143        7.6   9.200000   \n",
       "19  16.700000  17.957143       3.0  ...  26.257143        7.6   9.200000   \n",
       "21  17.133333  18.471429       0.0  ...  26.485714        8.0  10.666667   \n",
       "22  18.000000  18.757143       5.0  ...  26.300000        6.8  10.133333   \n",
       "23  16.700000  17.957143       3.0  ...  26.257143        7.6   9.200000   \n",
       "24  16.700000  17.957143       3.0  ...  26.257143        7.6   9.200000   \n",
       "25  15.333333  17.171429       2.0  ...  25.414286        7.3   9.300000   \n",
       "26  16.133333  18.257143       5.0  ...  25.628571        8.3   9.766667   \n",
       "27  15.533333  17.885714       0.0  ...  25.414286        6.0   8.966667   \n",
       "28  15.333333  17.585714       1.0  ...  25.271429        7.3   9.300000   \n",
       "29  14.066667  17.800000       5.0  ...  25.214286        4.5   6.533333   \n",
       "\n",
       "    MinTemp_7  Precip_3  Precip_7     SsMean   SsMean_1     SsMean_3  pred  \n",
       "0   10.371429  0.966667  1.071429   2260.510    135.420   595.573333   1.0  \n",
       "1   10.042857  1.166667  0.714286    936.380    132.570  1058.526667   1.0  \n",
       "2   10.371429  0.966667  1.071429   2260.510    135.420   595.573333   1.0  \n",
       "3   10.042857  1.166667  0.714286    936.380    132.570  1058.526667   1.0  \n",
       "4   10.071429  0.966667  0.528571  16864.435    249.440   259.771667   1.0  \n",
       "5    9.700000  0.866667  0.657143   1472.790    308.880   571.583333   1.0  \n",
       "6   11.857143  1.333333  0.771429    389.480     34.300    53.850000   0.0  \n",
       "7   10.042857  1.166667  0.714286    936.380    132.570  1058.526667   1.0  \n",
       "9   10.871429  0.766667  0.571429     84.000    936.380   384.130000   0.0  \n",
       "10  11.842857  1.366667  0.671429     26.930    389.480   145.020000   0.0  \n",
       "11  10.314286  0.433333  0.614286    294.060   1472.790   664.543333   0.0  \n",
       "12  10.414286  0.966667  0.414286   1483.110  16864.435  5707.848333   1.0  \n",
       "13  10.414286  0.966667  0.414286   1483.110  16864.435  5707.848333   1.0  \n",
       "14  10.428571  0.966667  0.528571    239.920   2260.510   895.566667   0.0  \n",
       "15  10.242857  0.000000  0.414286   1377.310    239.920   878.616667   1.0  \n",
       "16  10.242857  0.000000  0.414286   1377.310    239.920   878.616667   1.0  \n",
       "18  10.242857  0.000000  0.414286   1377.310    239.920   878.616667   1.0  \n",
       "19  10.242857  0.000000  0.414286   2054.905   1483.110  6198.995000   1.0  \n",
       "21  11.285714  0.533333  0.885714      9.180     26.930   150.236667   0.0  \n",
       "22  10.514286  0.266667  0.542857     89.860     84.000   384.316667   0.0  \n",
       "23  10.242857  0.000000  0.414286   2054.905   1483.110  6198.995000   1.0  \n",
       "24  10.242857  0.000000  0.414286   2054.905   1483.110  6198.995000   1.0  \n",
       "25   9.685714  1.000000  0.971429     44.370    768.500  1836.710000   0.0  \n",
       "26  10.300000  0.266667  0.614286     25.660     89.860   370.080000   0.0  \n",
       "27  10.814286  0.733333  0.885714     49.650      9.180   141.863333   0.0  \n",
       "28  10.342857  1.000000  0.942857     24.620   2292.600  1353.150000   0.0  \n",
       "29   9.957143  0.333333  0.642857     15.870     25.660    66.506667   0.0  \n",
       "\n",
       "[27 rows x 22 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighthouse",
   "language": "python",
   "name": "lighthouse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
