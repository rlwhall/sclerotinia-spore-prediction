{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I want to write for loops to summarize the differences of variable selection methods (VIF, LSR, high correlation, my own 'guesses', LASSO, divided by 'category' of variable (same day, day before, etc.)) between classification models (random forests, logistic, SVC). \n",
    "\n",
    "NB: try only data from 2019? A more complete data set, in terms of predictors (soil moisture, temp, etc.)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import normalize, scale, Normalizer, StandardScaler, OrdinalEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingRegressor, StackingRegressor\n",
    "\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import precision_score, f1_score, accuracy_score, roc_curve, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "import graphviz\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "from statistics import mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro:\n",
    "This is a practice with `for` loops to get some sense of how these models are performing. May or may not be the best code/data analysis procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in my data:\n",
    "ascospores = pd.read_csv(\"2018-19 asco and weather data for modeling.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SamplerNo', 'Location.x', 'SamplerType', 'ExtractionGroup',\n",
       "       'qPCR_Plate', 'JDay', 'Date', 'SampleID', 'SsCtMean', 'SsCtSD',\n",
       "       'SsMean', 'logSsMean', 'Censored', 'SsSD', 'SsScaled', 'SsClean',\n",
       "       'logSsClean', 'VolumeSampled', 'sporesPCM', 'logSPCM', 'TtCt', 'TtSD',\n",
       "       'Water.', 'logSsMean_t1', 'Location.y', 'Year', 'MeanWetness',\n",
       "       'DiffMeanWet', 'MeanWet_1d', 'MaxWetness', 'DiffMaxWet', 'MaxWet_1d',\n",
       "       'MinWetness', 'DiffMinWet', 'MinWet_1d', 'MeanTemp', 'DiffMeanT',\n",
       "       'MeanT_1d', 'MaxTemp', 'DiffMaxT', 'MaxT_1d', 'MinTemp', 'DiffMinT',\n",
       "       'MinT_1d', 'MeanRH', 'DiffMeanRH', 'MeanRH_1d', 'MaxRH', 'DiffMaxRH',\n",
       "       'MaxRH_1d', 'MinRH', 'DiffMinRH', 'MinRH_1d', 'DiffRH_0d', 'DiffRH_1d',\n",
       "       'DiffRH_2d', 'MaxDiffRH_2h', 'MaxDiffRH_3h', 'MeanVPD', 'DiffMeanVPD',\n",
       "       'MeanVPD_1d', 'MaxVPD', 'DiffMaxVPD', 'MaxVPD_1d', 'MinVPD',\n",
       "       'DiffMinVPD', 'TotalPrecip', 'Precip_1d', 'RainYN', 'MaxRain',\n",
       "       'MinRain', 'MeanWC', 'DiffMeanWC', 'MeanWC_1d', 'MaxWC', 'DiffMaxWC',\n",
       "       'MaxWC_1d', 'MinWC', 'DiffMinWC', 'MinWC_1d', 'MeanDP', 'DiffMeanDP',\n",
       "       'MeanDP_1d', 'MaxDP', 'DiffMaxDP', 'MaxDP_1d', 'MinDP', 'DiffMinDP',\n",
       "       'MinDP_1d', 'MeanSoilTemp', 'DiffMeanSoilT', 'MeanSoilT_1d',\n",
       "       'MaxSoilTemp', 'DiffMaxSoilT', 'MaxSoilT_1d', 'MinSoilTemp',\n",
       "       'DiffMinSoilT', 'MinSoilT_1d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascospores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any lines for which the response variable is missing:\n",
    "ascospores = ascospores.dropna(subset=['SsMean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 98)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select only the 2019 data - this is the most complete data set and will be used for this analysis\n",
    "asco_2019 = ascospores[ascospores['Year'] == 2019]\n",
    "asco_2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are redundant, not relevant, or contain no useful information\n",
    "asco_2019 = asco_2019.drop(['Date', 'SamplerType', 'ExtractionGroup','qPCR_Plate', 'SampleID', 'SsCtMean', \n",
    "                              'SsCtSD', 'Location.y', 'Censored', 'SsSD', 'SsScaled', 'SsClean', 'logSsClean',\n",
    "                              'VolumeSampled', 'sporesPCM', 'TtCt', 'TtSD', 'Water.', 'SamplerNo', 'Location.x',\n",
    "                              'MaxRain', 'MinRain', 'logSPCM'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 75)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['JDay', 'SsMean', 'logSsMean', 'logSsMean_t1', 'Year', 'MeanWetness',\n",
       "       'DiffMeanWet', 'MeanWet_1d', 'MaxWetness', 'DiffMaxWet', 'MaxWet_1d',\n",
       "       'MinWetness', 'DiffMinWet', 'MinWet_1d', 'MeanTemp', 'DiffMeanT',\n",
       "       'MeanT_1d', 'MaxTemp', 'DiffMaxT', 'MaxT_1d', 'MinTemp', 'DiffMinT',\n",
       "       'MinT_1d', 'MeanRH', 'DiffMeanRH', 'MeanRH_1d', 'MaxRH', 'DiffMaxRH',\n",
       "       'MaxRH_1d', 'MinRH', 'DiffMinRH', 'MinRH_1d', 'DiffRH_0d', 'DiffRH_1d',\n",
       "       'DiffRH_2d', 'MaxDiffRH_2h', 'MaxDiffRH_3h', 'MeanVPD', 'DiffMeanVPD',\n",
       "       'MeanVPD_1d', 'MaxVPD', 'DiffMaxVPD', 'MaxVPD_1d', 'MinVPD',\n",
       "       'DiffMinVPD', 'TotalPrecip', 'Precip_1d', 'RainYN', 'MeanWC',\n",
       "       'DiffMeanWC', 'MeanWC_1d', 'MaxWC', 'DiffMaxWC', 'MaxWC_1d', 'MinWC',\n",
       "       'DiffMinWC', 'MinWC_1d', 'MeanDP', 'DiffMeanDP', 'MeanDP_1d', 'MaxDP',\n",
       "       'DiffMaxDP', 'MaxDP_1d', 'MinDP', 'DiffMinDP', 'MinDP_1d',\n",
       "       'MeanSoilTemp', 'DiffMeanSoilT', 'MeanSoilT_1d', 'MaxSoilTemp',\n",
       "       'DiffMaxSoilT', 'MaxSoilT_1d', 'MinSoilTemp', 'DiffMinSoilT',\n",
       "       'MinSoilT_1d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(asco_2019.shape)\n",
    "asco_2019.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still contains some rendundant/not useful columns ('JDay', 'logSsMean', etc.), but I'll deal with them below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and test data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only doing trainvalid and test data sets for this analysis due to smaller n\n",
    "asco_trainvalid, asco_test = train_test_split(asco_2019, test_size = 0.2, random_state = 44)\n",
    "#asco_train, asco_valid = train_test_split(asco_trainvalid, test_size = 0.2, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainvalid = asco_trainvalid['SsMean']\n",
    "y_test = asco_test['SsMean']\n",
    "y_all = asco_2019['SsMean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainvalid = asco_trainvalid.drop(['SsMean'], axis = 1)\n",
    "X_test = asco_test.drop(['SsMean'], axis = 1)\n",
    "X_all = asco_2019.drop(['SsMean'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make data frames for X data sets; export these for use in other programs (R)\n",
    "\n",
    "X_trainvalid_df = pd.DataFrame(X_trainvalid)\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_all_df = pd.DataFrame(X_all)\n",
    "\n",
    "#X_train_df.columns = new_columns\n",
    "#X_valid_df.columns = new_columns\n",
    "#X_test_df.columns = new_columns\n",
    "\n",
    "X_trainvalid_df.to_csv(\"~/Desktop/Data/Field Data Analysis/Modeling Data Sets from Python/Variable Selection Data Sets/X_trainvalid.csv\")\n",
    "X_test_df.to_csv(\"~/Desktop/Data/Field Data Analysis/Modeling Data Sets from Python/Variable Selection Data Sets/X_test.csv\")\n",
    "X_all_df.to_csv(\"~/Desktop/Data/Field Data Analysis/Modeling Data Sets from Python/Variable Selection Data Sets/X_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "y100_trainvalid = np.where(y_trainvalid >= 100, 1, 0)\n",
    "y100_test = np.where(y_test >= 100, 1, 0)\n",
    "y100_all = np.where(y_all >= 100, 1, 0)\n",
    "\n",
    "y200_trainvalid = np.where(y_trainvalid >= 200, 1, 0)\n",
    "y200_test = np.where(y_test >= 200, 1, 0)\n",
    "y200_all = np.where(y_all >= 200, 1, 0)\n",
    "\n",
    "y500_trainvalid = np.where(y_trainvalid >= 500, 1, 0)\n",
    "y500_test = np.where(y_test >= 500, 1, 0)\n",
    "y500_all = np.where(y_all >= 500, 1, 0)\n",
    "\n",
    "y1000_trainvalid = np.where(y_trainvalid >= 1000, 1, 0)\n",
    "y1000_test = np.where(y_test >= 1000, 1, 0)\n",
    "y1000_all = np.where(y_all >= 1000, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proportion of Ones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y100_trainvalid</th>\n",
       "      <td>0.654472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y100_test</th>\n",
       "      <td>0.693548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y100_all</th>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y200_trainvalid</th>\n",
       "      <td>0.483740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y200_test</th>\n",
       "      <td>0.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y200_all</th>\n",
       "      <td>0.496753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y500_trainvalid</th>\n",
       "      <td>0.252033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y500_test</th>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y500_all</th>\n",
       "      <td>0.253247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y1000_trainvalid</th>\n",
       "      <td>0.130081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y1000_test</th>\n",
       "      <td>0.080645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y1000_all</th>\n",
       "      <td>0.120130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Proportion of Ones\n",
       "y100_trainvalid             0.654472\n",
       "y100_test                   0.693548\n",
       "y100_all                    0.662338\n",
       "y200_trainvalid             0.483740\n",
       "y200_test                   0.548387\n",
       "y200_all                    0.496753\n",
       "y500_trainvalid             0.252033\n",
       "y500_test                   0.258065\n",
       "y500_all                    0.253247\n",
       "y1000_trainvalid            0.130081\n",
       "y1000_test                  0.080645\n",
       "y1000_all                   0.120130"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y = [y100_trainvalid, y100_test, y100_all,\n",
    "         y200_trainvalid, y200_test, y200_all,\n",
    "         y500_trainvalid, y500_test, y500_all,\n",
    "         y1000_trainvalid, y1000_test, y1000_all]\n",
    "\n",
    "y_means = []\n",
    "for y in all_y: \n",
    "    y_means.append(y.mean())\n",
    "\n",
    "y_names = ['y100_trainvalid', 'y100_test', 'y100_all',\n",
    "           'y200_trainvalid', 'y200_test', 'y200_all',\n",
    "           'y500_trainvalid', 'y500_test', 'y500_all',\n",
    "           'y1000_trainvalid', 'y1000_test', 'y1000_all']\n",
    "\n",
    "y_df = pd.DataFrame(data=y_means, index=y_names, columns=[\"Proportion of Ones\"])\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.96"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine how many 'cases' there are in the y1000_test group - the low number of test cases in this set is\n",
    "#   an issue in interpreting the AUC below\n",
    "len(y1000_test) * 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the test sets for use in R, or other programs:\n",
    "# y_names defined above\n",
    "y_names = ['y100_trainvalid', 'y100_test', 'y100_all',\n",
    "         'y200_trainvalid', 'y200_test', 'y200_all',\n",
    "         'y500_trainvalid', 'y500_test', 'y500_all',\n",
    "         'y1000_trainvalid', 'y1000_test', 'y1000_all']\n",
    "\n",
    "y_data = [y100_trainvalid, y100_test, y100_all,\n",
    "         y200_trainvalid, y200_test, y200_all,\n",
    "         y500_trainvalid, y500_test, y500_all,\n",
    "         y1000_trainvalid, y1000_test, y1000_all]\n",
    "file_path = \"~/Desktop/Data/Field Data Analysis/Modeling Data Sets from Python/Variable Selection Data Sets/\"\n",
    "\n",
    "for i in np.arange(0, len(y_data)):\n",
    "    to_save = pd.DataFrame(list(y_data[i]))\n",
    "    to_save.to_csv(file_path + y_names[i] + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also save the raw y-data\n",
    "ylog_all = np.log10(y_all + 1)\n",
    "ylog_all.to_csv(file_path + \"ylog_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable selection sets:\n",
    "features_all = ['logSsMean_t1', 'MeanWetness', 'DiffMeanWet', 'MeanWet_1d',\n",
    "       'MaxWetness', 'DiffMaxWet', 'MaxWet_1d', 'MinWetness', 'DiffMinWet',\n",
    "       'MinWet_1d', 'MeanTemp', 'DiffMeanT', 'MeanT_1d', 'MaxTemp', 'DiffMaxT',\n",
    "       'MaxT_1d', 'MinTemp', 'DiffMinT', 'MinT_1d', 'MeanRH', 'DiffMeanRH',\n",
    "       'MeanRH_1d', 'MaxRH', 'DiffMaxRH', 'MaxRH_1d', 'MinRH', 'DiffMinRH',\n",
    "       'MinRH_1d', 'DiffRH_0d', 'DiffRH_1d', 'DiffRH_2d', 'MaxDiffRH_2h',\n",
    "       'MaxDiffRH_3h', 'MeanVPD', 'DiffMeanVPD', 'MeanVPD_1d', 'MaxVPD',\n",
    "       'DiffMaxVPD', 'MaxVPD_1d', 'MinVPD', 'DiffMinVPD', 'TotalPrecip',\n",
    "       'Precip_1d', 'RainYN', 'MaxRain', 'MinRain', 'MeanWC', 'DiffMeanWC',\n",
    "       'MeanWC_1d', 'MaxWC', 'DiffMaxWC', 'MaxWC_1d', 'MinWC', 'DiffMinWC',\n",
    "       'MinWC_1d', 'MeanDP', 'DiffMeanDP', 'MeanDP_1d', 'MaxDP', 'DiffMaxDP',\n",
    "       'MaxDP_1d', 'MinDP', 'DiffMinDP', 'MinDP_1d', 'MeanSoilTemp',\n",
    "       'DiffMeanSoilT', 'MeanSoilT_1d', 'MaxSoilTemp', 'DiffMaxSoilT',\n",
    "       'MaxSoilT_1d', 'MinSoilTemp', 'DiffMinSoilT', 'MinSoilT_1d', 'RainYN']\n",
    "# see code below for LASSO feature selection\n",
    "# this set of variables depends on what the response variable is - i.e. where I set the threshold or whether I use \n",
    "#   a continuous response variable. So... for now I'll stick with the continuous response variable \n",
    "#   (ylog_all = log(SsMean +1))\n",
    "features_lasso = ['logSsMean_t1', 'TotalPrecip', 'RainYN', 'DiffMaxWet', 'MinSoilT_1d', 'MeanRH', \n",
    "                 'MeanSoilT_1d', 'MeanWC_1d', 'MeanWC', 'DiffMinSoilT', 'DiffMinDP', 'MaxDP_1d', 'DiffRH_1d',\n",
    "                 'MaxTemp', 'DiffMeanSoilT']\n",
    "# identified by VIF function in R - found this algorithm on internet\n",
    "features_VIF = [\"logSsMean_t1\", \"MeanWetness\", \"MeanWet_1d\", \"MaxWetness\", \"MaxWet_1d\", \"MinWetness\",\n",
    "                \"MinWet_1d\", \"MinTemp\", \"MinT_1d\", \"DiffRH_0d\", \"DiffRH_1d\", \"DiffRH_2d\", \"MaxDiffRH_2h\",\n",
    "                \"DiffMeanVPD\", \"TotalPrecip\", \"Precip_1d\", \"MeanWC\", \"DiffMeanWC\", \"MinWC\", \"DiffMaxDP\",   \n",
    "                \"MaxDP_1d\", \"DiffMinDP\", \"MinDP_1d\", \"DiffMaxSoilT\", \"MaxSoilT_1d\", \"DiffMinSoilT\",\n",
    "                \"MinSoilT_1d\", \"RainYN\"]\n",
    "features_biology = [\"logSsMean_t1\", \"MaxTemp\", \"MeanRH\", \"MaxDiffRH_3h\", \"Precip_1d\"]\n",
    "features_no_correlation = [\"logSsMean_t1\", \"DiffMinWet\", \"MaxTemp\", \"DiffMaxT\", \"MaxT_1d\", \"MaxRH\", \"DiffMaxRH\", \"MaxRH_1d\", \n",
    "                           \"MinRH\", \"DiffMinRH\", \"MinRH_1d\", \"MaxDiffRH_2h\", \"MeanVPD\", \"DiffMeanVPD\", \"MeanVPD_1d\",\n",
    "                           \"MaxVPD\", \"DiffMaxVPD\", \"MaxVPD_1d\", \"MinVPD\", \"DiffMinVPD\", \"MaxRain\", \"MeanWC\", \n",
    "                           \"DiffMeanWC\", \"MeanWC_1d\", \"MaxWC\", \"DiffMaxWC\", \"MaxWC_1d\", \"MinWC\", \"DiffMinWC\", \n",
    "                           \"MinWC_1d\", \"MaxDP\", \"DiffMaxDP\", \"MaxDP_1d\", \"MinDP\", \"DiffMinDP\", \"MinDP_1d\",\n",
    "                           \"MeanSoilTemp\", \"DiffMeanSoilT\", \"MeanSoilT_1d\", \"MaxSoilTemp\", \"DiffMaxSoilT\", \n",
    "                           \"MaxSoilT_1d\", \"MinSoilTemp\", \"DiffMinSoilT\", \"MinSoilT_1d\"]\n",
    "# omit this approach for now - I don't totally understand the theory/applications behind partial least squares\n",
    "#    regression\n",
    "#features_LSR = []\n",
    "## Same sets as in the R code\n",
    "features_same_day = ['MeanWetness', 'MaxWetness', 'MinWetness', 'MeanTemp', 'MaxTemp', 'MinTemp',\n",
    "                      'MeanRH', 'MaxRH', 'MinRH', 'MeanVPD', 'MaxVPD', 'MinVPD', 'TotalPrecip',\n",
    "                      'RainYN', 'MeanWC', 'MaxWC', 'MinWC', 'MeanDP', 'MaxDP', 'MinDP',\n",
    "                      'MeanSoilTemp', 'MaxSoilTemp', 'MinSoilTemp']\n",
    "features_previous_day = ['logSsMean_t1', 'MeanWet_1d', 'MaxWet_1d', 'MinWet_1d', 'MeanT_1d', 'MaxT_1d', 'MinT_1d',\n",
    "                        'MeanRH_1d', 'MaxRH_1d', 'MinRH_1d', 'DiffRH_1d', 'MeanVPD_1d', \n",
    "                        'MaxVPD_1d', 'Precip_1d', 'MeanWC_1d', 'MaxWC_1d', 'MinWC_1d', 'MeanDP_1d',\n",
    "                        'MaxDP_1d', 'MinDP_1d', 'MeanSoilT_1d', 'MaxSoilT_1d', 'MinSoilT_1d']\n",
    "features_differences = ['DiffMeanWet', 'DiffMaxWet', 'DiffMinWet', 'DiffMeanT', 'DiffMaxT', 'DiffMinT',\n",
    "                  'DiffMeanRH', 'DiffMaxRH', 'DiffMinRH', 'DiffRH_0d', 'DiffRH_1d', 'DiffRH_2d',\n",
    "                  'MaxDiffRH_2h', 'MaxDiffRH_3h', 'DiffMeanVPD', 'DiffMaxVPD', 'DiffMinVPD', \n",
    "                  'DiffMeanWC', 'DiffMaxWC', 'DiffMinWC', 'DiffMeanDP', 'DiffMaxDP', 'DiffMinDP',\n",
    "                  'DiffMeanSoilT', 'DiffMaxSoilT', 'DiffMinSoilT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [features_all, features_lasso, features_VIF, features_biology, features_no_correlation,\n",
    "               features_same_day, features_previous_day, features_differences]\n",
    "feature_set_names = ['features_all', 'features_lasso', 'features_VIF', 'features_biology', 'features_no_correlation',\n",
    "                     'features_same_day', 'features_previous_day', 'features_differences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to LASSO I need to impute and scale my data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB: I'm going to violate the Golden Rule here by using the whole data set to do the variable selection - then I will use the trainvalid and test data sets to evaluate the model. I'm doing this because my data set is relatively small, and I'll be using which ever methods I determine are best for analysis of data over the next ~2 years (i.e. this is model development mid-way through the research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['logSsMean_t1', 'MeanWetness', 'DiffMeanWet', 'MeanWet_1d', 'MaxWetness', 'DiffMaxWet',\n",
    "       'MaxWet_1d', 'MinWetness', 'DiffMinWet', 'MinWet_1d', 'MeanTemp',\n",
    "       'DiffMeanT', 'MeanT_1d', 'MaxTemp', 'DiffMaxT', 'MaxT_1d', 'MinTemp',\n",
    "       'DiffMinT', 'MinT_1d', 'MeanRH', 'DiffMeanRH', 'MeanRH_1d', 'MaxRH',\n",
    "       'DiffMaxRH', 'MaxRH_1d', 'MinRH', 'DiffMinRH', 'MinRH_1d', 'DiffRH_0d',\n",
    "       'DiffRH_1d', 'DiffRH_2d', 'MaxDiffRH_2h', 'MaxDiffRH_3h', 'MeanVPD',\n",
    "       'DiffMeanVPD', 'MeanVPD_1d', 'MaxVPD', 'DiffMaxVPD', 'MaxVPD_1d',\n",
    "       'MinVPD', 'DiffMinVPD', 'TotalPrecip', 'Precip_1d',  'MeanWC',\n",
    "       'DiffMeanWC', 'MeanWC_1d', 'MaxWC', 'DiffMaxWC', 'MaxWC_1d', 'MinWC',\n",
    "       'DiffMinWC', 'MinWC_1d', 'MeanDP', 'DiffMeanDP', 'MeanDP_1d', 'MaxDP',\n",
    "       'DiffMaxDP', 'MaxDP_1d', 'MinDP', 'DiffMinDP', 'MinDP_1d',\n",
    "       'MeanSoilTemp', 'DiffMeanSoilT', 'MeanSoilT_1d', 'MaxSoilTemp',\n",
    "       'DiffMaxSoilT', 'MaxSoilT_1d', 'MinSoilTemp', 'DiffMinSoilT',\n",
    "       'MinSoilT_1d']\n",
    "categorical_features = ['RainYN']\n",
    "drop_features = ['JDay', 'Year', 'SsMean', 'logSsMean', 'logSPCM',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numeric transformer\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', IterativeImputer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create categorical transformer\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric', numeric_transformer, numeric_features),\n",
    "    ('categorical', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(asco_trainvalid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = preprocessor.named_transformers_['categorical'].named_steps['onehot']\n",
    "ohe_feature_names = list(ohe.get_feature_names(categorical_features))\n",
    "new_columns = numeric_features + ohe_feature_names\n",
    "new_columns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frames of the features\n",
    "X_trainvalid = pd.DataFrame(preprocessor.transform(asco_trainvalid),  index=asco_trainvalid.index, \n",
    "                            columns=new_columns)\n",
    "X_test = pd.DataFrame(preprocessor.transform(asco_test),  index=asco_test.index,  columns=new_columns)\n",
    "X_all = pd.DataFrame(preprocessor.transform(asco_2019),  index=asco_2019.index,  columns=new_columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I can do LASSO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO feature selection - need scaled features\n",
    "# ONE OPTION FOR DOING THIS BELOW: this is using the transformed/encoded X data set and using the binary y\n",
    "#                                  target\n",
    "# Lasso:\n",
    "larcv = LassoCV(n_alphas=100, cv = 10, max_iter = 10000) \n",
    "\n",
    "#y_data_sets = [y100_trainvalid, y200_trainvalid, y500_trainvalid, y1000_trainvalid]\n",
    "y_data_sets = [ylog_all, y100_all, y200_all, y500_all, y1000_all]\n",
    "larcv_coefs = pd.DataFrame(index = X_all.columns)\n",
    "\n",
    "# a for loop to perform all fits at once:\n",
    "for y in y_data_sets:\n",
    "    larcv.fit(X_all, y)\n",
    "    larcv_ycoefs = pd.DataFrame(data=abs(larcv.coef_), index=X_all.columns)\n",
    "    \n",
    "    larcv_coefs = pd.concat([larcv_coefs, larcv_ycoefs], axis=1)\n",
    "    \n",
    "larcv_coefs.columns = ['ylog', 'y100', 'y200', 'y500', 'y1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ylog</th>\n",
       "      <th>y100</th>\n",
       "      <th>y200</th>\n",
       "      <th>y500</th>\n",
       "      <th>y1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logSsMean_t1</th>\n",
       "      <td>0.140205</td>\n",
       "      <td>0.077044</td>\n",
       "      <td>0.070383</td>\n",
       "      <td>0.022640</td>\n",
       "      <td>0.015519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalPrecip</th>\n",
       "      <td>0.119159</td>\n",
       "      <td>0.060387</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RainYN_1.0</th>\n",
       "      <td>0.098137</td>\n",
       "      <td>0.062156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffMaxWet</th>\n",
       "      <td>0.073328</td>\n",
       "      <td>0.035758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinSoilT_1d</th>\n",
       "      <td>0.063239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanRH</th>\n",
       "      <td>0.040461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045987</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanSoilT_1d</th>\n",
       "      <td>0.032151</td>\n",
       "      <td>0.059527</td>\n",
       "      <td>0.042376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanWC_1d</th>\n",
       "      <td>0.021931</td>\n",
       "      <td>0.020178</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanWC</th>\n",
       "      <td>0.019865</td>\n",
       "      <td>0.016203</td>\n",
       "      <td>0.014361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffMinSoilT</th>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffMinDP</th>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDP_1d</th>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffRH_1d</th>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxTemp</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffMeanSoilT</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffRH_2d</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDiffRH_2h</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffMinVPD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanT_1d</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxRH_1d</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxWC_1d</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffMaxDP</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinT_1d</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinWet_1d</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ylog      y100      y200      y500     y1000\n",
       "logSsMean_t1   0.140205  0.077044  0.070383  0.022640  0.015519\n",
       "TotalPrecip    0.119159  0.060387  0.013555  0.000000  0.000000\n",
       "RainYN_1.0     0.098137  0.062156  0.000000  0.000000  0.000000\n",
       "DiffMaxWet     0.073328  0.035758  0.000000  0.000000  0.000000\n",
       "MinSoilT_1d    0.063239  0.000000  0.000000  0.000000  0.000000\n",
       "MeanRH         0.040461  0.000000  0.000000  0.045987  0.006877\n",
       "MeanSoilT_1d   0.032151  0.059527  0.042376  0.000000  0.000000\n",
       "MeanWC_1d      0.021931  0.020178  0.005226  0.000541  0.000000\n",
       "MeanWC         0.019865  0.016203  0.014361  0.000000  0.000000\n",
       "DiffMinSoilT   0.004746  0.013145  0.002026  0.000000  0.000000\n",
       "DiffMinDP      0.004513  0.000000  0.000000  0.007584  0.000000\n",
       "MaxDP_1d       0.003916  0.016005  0.000000  0.000000  0.000000\n",
       "DiffRH_1d      0.000509  0.000000  0.000000  0.000000  0.004646\n",
       "MaxTemp        0.000332  0.006633  0.000000  0.000000  0.000000\n",
       "DiffMeanSoilT  0.000327  0.001693  0.000000  0.000000  0.000000\n",
       "DiffRH_2d      0.000000  0.008484  0.000000  0.000000  0.007689\n",
       "MaxDiffRH_2h   0.000000  0.000000  0.000000  0.000000  0.016081\n",
       "DiffMinVPD     0.000000  0.000000  0.000000  0.000000  0.024034\n",
       "MeanT_1d       0.000000  0.000000  0.012833  0.004825  0.000000\n",
       "MaxRH_1d       0.000000  0.017098  0.000000  0.000000  0.000000\n",
       "MaxWC_1d       0.000000  0.027048  0.000000  0.000000  0.000000\n",
       "DiffMaxDP      0.000000  0.000000  0.000000  0.000000  0.010204\n",
       "MinT_1d        0.000000  0.000000  0.000000  0.000000  0.004088\n",
       "MinWet_1d      0.000000  0.000778  0.002097  0.001573  0.000247"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display results; remove variables that weren't selected in any of the models (i.e. their coefficient = 0)\n",
    "larcv_coefs[(larcv_coefs.T > 1e-6).any()].sort_values(by='ylog', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so some similarities between data sets, but mostly pretty different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is to assess how the scoring functions of `RandomForestClassifier()` work. The first part implements essentially what I'll be doing for the remainder of this analysis (the automated imputation, transformation, and hyperparameter selection) and spits out an AUC value for the test data set. The next section does all those steps manually, uses the the same hyperparameters as the optimal model identified previously, and manually calculates the AUC. Spoiler alert: the AUCs are pretty different between the two methods... why?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6217870257037944"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All steps in the analysis performed at once/automated; the feature set I'm using is the set of features selected\n",
    "#   by LASSO:\n",
    "\n",
    "num_features = ['logSsMean_t1', 'TotalPrecip', 'DiffMaxWet', 'MinSoilT_1d', 'MeanRH', \n",
    "             'MeanSoilT_1d', 'MeanWC_1d', 'MeanWC', 'DiffMinSoilT', 'DiffMinDP', 'MaxDP_1d', 'DiffRH_1d',\n",
    "             'MaxTemp', 'DiffMeanSoilT'] \n",
    "cat_features = ['RainYN']\n",
    "\n",
    "# create preprocessors\n",
    "numeric_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    " ])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric', numeric_transformer, num_features),\n",
    "    ('categorical', categorical_transformer, cat_features)\n",
    "])\n",
    "\n",
    "# create rf pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestClassifier(random_state = 545))\n",
    "])\n",
    "\n",
    "# create param_dist dict\n",
    "param_dist = {\n",
    "    'model__n_estimators'     : scipy.stats.randint(low=10, high=100),\n",
    "    'model__max_depth'        : scipy.stats.randint(low=3, high=10),\n",
    "    'model__class_weight'     : (None, \"balanced\")\n",
    "}\n",
    "\n",
    "# create randomized search CV\n",
    "random_search_auc = RandomizedSearchCV(rf_pipeline,\n",
    "                                param_distributions= param_dist,\n",
    "                                 n_iter = 30,\n",
    "                                 cv = 10,\n",
    "                                 scoring = 'roc_auc', # maximize the AUC score (ways to do multiplie criteria)\n",
    "                                 verbose = 1,\n",
    "                                 random_state = 454)\n",
    "\n",
    "random_search_auc.fit(X_trainvalid, y100_trainvalid) \n",
    "auc_score = ()\n",
    "auc_score = random_search_auc.score(X_test, y100_test)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, is this actually doing what I want it to do? Try to rerun the analysis but with me in charge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__class_weight': 'balanced',\n",
       " 'model__max_depth': 3,\n",
       " 'model__n_estimators': 79}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the optimal hyperparameters from the RandomizedSearchCV()\n",
    "random_search_auc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (unrelated but eventually very useful to have:)\n",
    "# FINALLY figured out how to get feature importances from the RandomizedSearchCV() pipeline... uggghhhhh\n",
    "importances = random_search_auc.best_estimator_.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now repeat the above but now do it manually, using the same hyperparameters specified as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my own rf object using the above hyperparameters\n",
    "rf_trial = RandomForestClassifier(class_weight = 'balanced', max_depth = 3, n_estimators = 79, random_state = 545)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['logSsMean_t1', 'TotalPrecip', 'DiffMaxWet', 'MinSoilT_1d', 'MeanRH', \n",
    "             'MeanSoilT_1d', 'MeanWC_1d', 'MeanWC', 'DiffMinSoilT', 'DiffMinDP', 'MaxDP_1d', 'DiffRH_1d',\n",
    "             'MaxTemp', 'DiffMeanSoilT'] \n",
    "cat_features = ['RainYN'] \n",
    "\n",
    "# create preprocessor\n",
    "numeric_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    " ])\n",
    "\n",
    "# question: what happens if there are no categorical features? - sort out in the debugging stage\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric', numeric_transformer, num_features),\n",
    "    ('categorical', categorical_transformer, cat_features)\n",
    "])\n",
    "\n",
    "preprocessor.fit(X_trainvalid)\n",
    "X_tv_enc = preprocessor.transform(X_trainvalid)\n",
    "X_test_enc = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_trial.fit(X_tv_enc, y100_trainvalid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the for loop above, I was aiming to maximize roc_auc, to do this manually:\n",
    "rf_probs = rf_trial.predict_proba(X_test_enc)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6774193548387096"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_trial.score(X_test_enc, y100_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6719706242350061"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_rf = roc_auc_score(y100_test, rf_probs)\n",
    "auc_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this value of 0.67 is greater than the value obtained from the CV-method (score = 0.62) - why the difference?!... and even my manual calculation of it is different from the `score` function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuing on with the remainder of the analysis..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I've written a `for` loop to perform a random forests analysis (hyperparameters determined by `RandomizedSearchCV()`) for the y100 data set. The code performs 7 sets of analysis (one for each subset of features), and is repeated below for each threshold (100, 200, 500, 1000)... eventually this could all be in one loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring criteria is for AUC. I wasn't certain this was doing what I wanted it to do, so I eventually included some lines in the `for` loop (see the two iterations of the 1000-threshold loops below) wherein I calculated it manually. The results are similar, but not the same, and I'm not sure why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 13.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   47.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  4.5min finished\n"
     ]
    }
   ],
   "source": [
    "# threshold = 100 spores per day\n",
    "\n",
    "auc_test_scores = []\n",
    "\n",
    "## NB: data sets called in this loop have not been preprocessed - doing so is part of the pipeline/program\n",
    "for features in feature_sets:\n",
    "    # create numeric and categorical feature lists for pipeline - these are based on the selected ones from\n",
    "    #     above\n",
    "    num_features = [i for i in features if i in numeric_features] # some function to select numeric features\n",
    "    cat_features = [i for i in features if i in categorical_features] # if this is a blank list, I believe that's fine\n",
    "    \n",
    "    # create preprocessor\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "    ])\n",
    "    \n",
    "    #if len(cat_features) > 0:   # check if cat_features is empty, as this may cause problems in the pipeline\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "     ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, num_features),\n",
    "        ('categorical', categorical_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    # create rf pipeline\n",
    "    rf_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestClassifier(random_state = 545))\n",
    "    ])\n",
    "    # create param_dist dict\n",
    "    param_dist = {\n",
    "        'model__n_estimators'     : scipy.stats.randint(low=10, high=100),\n",
    "        'model__max_depth'        : scipy.stats.randint(low=3, high=10),\n",
    "        'model__class_weight'     : (None, \"balanced\")\n",
    "    }\n",
    "\n",
    "    # create randomized search CV\n",
    "    random_search_auc = RandomizedSearchCV(rf_pipeline,\n",
    "                                    param_distributions= param_dist,\n",
    "                                     n_iter = 30,\n",
    "                                     cv = 10,\n",
    "                                     scoring = 'roc_auc', # maximize the auc score (ways to do multiplie criteria)\n",
    "                                     verbose = 1,\n",
    "                                     random_state = 454)\n",
    "    random_search_auc.fit(X_trainvalid, y100_trainvalid) \n",
    "    auc_score = ()\n",
    "    auc_score = random_search_auc.score(X_test, y100_test)\n",
    "    auc_test_scores.append(auc_score)\n",
    "    \n",
    "    auc_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features_all</th>\n",
       "      <td>0.560588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_lasso</th>\n",
       "      <td>0.621787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_VIF</th>\n",
       "      <td>0.625459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_biology</th>\n",
       "      <td>0.410037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_no_correlation</th>\n",
       "      <td>0.512852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_same_day</th>\n",
       "      <td>0.555692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_previous_day</th>\n",
       "      <td>0.521420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_differences</th>\n",
       "      <td>0.455324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             y100\n",
       "features_all             0.560588\n",
       "features_lasso           0.621787\n",
       "features_VIF             0.625459\n",
       "features_biology         0.410037\n",
       "features_no_correlation  0.512852\n",
       "features_same_day        0.555692\n",
       "features_previous_day    0.521420\n",
       "features_differences     0.455324"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = auc_test_scores, index = feature_set_names, columns = ['y100'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so pretty bad AUC scores. Interestingly, some are LESS than 0.50 - model fitting portion learning false relationships?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   47.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "# repeat above, but for 200 ascospores threshold:\n",
    "\n",
    "auc_test_scores = []\n",
    "\n",
    "for features in feature_sets:\n",
    "    # create numeric and categorical feature lists for pipeline - these are based on the selected ones from\n",
    "    #     above\n",
    "    num_features = [i for i in features if i in numeric_features] \n",
    "    cat_features = [i for i in features if i in categorical_features] \n",
    "    \n",
    "    # create preprocessor\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "     ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, num_features),\n",
    "        ('categorical', categorical_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    # create rf pipeline\n",
    "    rf_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestClassifier(random_state = 545))\n",
    "    ])\n",
    "    # create param_dist dict\n",
    "    param_dist = {\n",
    "        'model__n_estimators'     : scipy.stats.randint(low=10, high=100),\n",
    "        'model__max_depth'        : scipy.stats.randint(low=3, high=10),\n",
    "        'model__class_weight'     : (None, \"balanced\")\n",
    "    }\n",
    "\n",
    "    # create randomized search CV\n",
    "    random_search_auc = RandomizedSearchCV(rf_pipeline,\n",
    "                                    param_distributions= param_dist,\n",
    "                                     n_iter = 30,\n",
    "                                     cv = 10,\n",
    "                                     scoring = 'roc_auc', # maximize the auc score (ways to do multiplie criteria)\n",
    "                                     verbose = 1,\n",
    "                                     random_state = 454)\n",
    "\n",
    "    random_search_auc.fit(X_trainvalid, y200_trainvalid) \n",
    "    auc_score = ()\n",
    "    auc_score = random_search_auc.score(X_test, y200_test)\n",
    "    auc_test_scores.append(auc_score)\n",
    "    \n",
    "    auc_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features_all</th>\n",
       "      <td>0.665441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_lasso</th>\n",
       "      <td>0.510504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_VIF</th>\n",
       "      <td>0.513655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_biology</th>\n",
       "      <td>0.476891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_no_correlation</th>\n",
       "      <td>0.548319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_same_day</th>\n",
       "      <td>0.581933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_previous_day</th>\n",
       "      <td>0.511555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_differences</th>\n",
       "      <td>0.509454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             y200\n",
       "features_all             0.665441\n",
       "features_lasso           0.510504\n",
       "features_VIF             0.513655\n",
       "features_biology         0.476891\n",
       "features_no_correlation  0.548319\n",
       "features_same_day        0.581933\n",
       "features_previous_day    0.511555\n",
       "features_differences     0.509454"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = auc_test_scores, index = feature_set_names, columns = ['y200'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, pretty bad scores here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 13.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   44.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "# as above, for threshold = 500 spores per day\n",
    "\n",
    "auc_test_scores = []\n",
    "\n",
    "for features in feature_sets:\n",
    "    num_features = [i for i in features if i in numeric_features] \n",
    "    cat_features = [i for i in features if i in categorical_features] \n",
    "    \n",
    "    # create preprocessor\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(sample_posterior = True, random_state = 356)) # was having convergence warnings\n",
    "                               # when I left 'sample_posterior = False' (the default)\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "     ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, num_features),\n",
    "        ('categorical', categorical_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    # create rf pipeline\n",
    "    rf_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestClassifier(random_state = 545))\n",
    "    ])\n",
    "    # create param_dist dict\n",
    "    param_dist = {\n",
    "        'model__n_estimators'     : scipy.stats.randint(low=10, high=100),\n",
    "        'model__max_depth'        : scipy.stats.randint(low=3, high=10),\n",
    "        'model__class_weight'     : (None, \"balanced\")\n",
    "    }\n",
    "\n",
    "    # create randomized search CV\n",
    "    random_search_auc = RandomizedSearchCV(rf_pipeline,\n",
    "                                    param_distributions= param_dist,\n",
    "                                     n_iter = 30,\n",
    "                                     cv = 10,\n",
    "                                     scoring = 'roc_auc', # maximize the auc score (ways to do multiplie criteria)\n",
    "                                     verbose = 1,\n",
    "                                     random_state = 454)\n",
    "\n",
    "    random_search_auc.fit(X_trainvalid, y500_trainvalid) \n",
    "    auc_score = ()\n",
    "    auc_score = random_search_auc.score(X_test, y500_test)\n",
    "    auc_test_scores.append(auc_score)\n",
    "    \n",
    "    auc_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features_all</th>\n",
       "      <td>0.692935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_lasso</th>\n",
       "      <td>0.559783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_VIF</th>\n",
       "      <td>0.513587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_biology</th>\n",
       "      <td>0.633152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_no_correlation</th>\n",
       "      <td>0.591712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_same_day</th>\n",
       "      <td>0.501359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_previous_day</th>\n",
       "      <td>0.683424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_differences</th>\n",
       "      <td>0.586957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             y500\n",
       "features_all             0.692935\n",
       "features_lasso           0.559783\n",
       "features_VIF             0.513587\n",
       "features_biology         0.633152\n",
       "features_no_correlation  0.591712\n",
       "features_same_day        0.501359\n",
       "features_previous_day    0.683424\n",
       "features_differences     0.586957"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = auc_test_scores, index = feature_set_names, columns = ['y500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 13.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   46.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  4.1min finished\n"
     ]
    }
   ],
   "source": [
    "# repeat above, but for threshold = 1,000 spores per day:\n",
    "\n",
    "auc_test_scores = []\n",
    "\n",
    "for features in feature_sets:\n",
    "    num_features = [i for i in features if i in numeric_features]\n",
    "    cat_features = [i for i in features if i in categorical_features] \n",
    "    \n",
    "    # create preprocessor\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "     ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, num_features),\n",
    "        ('categorical', categorical_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    # create rf pipeline\n",
    "    rf_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestClassifier(random_state = 545))\n",
    "    ])\n",
    "    # create param_dist dict\n",
    "    param_dist = {\n",
    "        'model__n_estimators'     : scipy.stats.randint(low=10, high=100),\n",
    "        'model__max_depth'        : scipy.stats.randint(low=3, high=10),\n",
    "        'model__class_weight'     : (None, \"balanced\")\n",
    "    }\n",
    "\n",
    "    # create randomized search CV\n",
    "    random_search_auc = RandomizedSearchCV(rf_pipeline,\n",
    "                                    param_distributions= param_dist,\n",
    "                                     n_iter = 30,\n",
    "                                     cv = 10,\n",
    "                                     scoring = 'roc_auc', # maximize the auc score (ways to do multiplie criteria)\n",
    "                                     verbose = 1,\n",
    "                                     random_state = 454)\n",
    "\n",
    "    random_search_auc.fit(X_trainvalid, y1000_trainvalid) \n",
    "    auc_score = ()\n",
    "    auc_score = random_search_auc.score(X_test, y1000_test)\n",
    "    auc_test_scores.append(auc_score)\n",
    "    \n",
    "    auc_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features_all</th>\n",
       "      <td>0.870175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_lasso</th>\n",
       "      <td>0.807018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_VIF</th>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_biology</th>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_no_correlation</th>\n",
       "      <td>0.849123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_same_day</th>\n",
       "      <td>0.705263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_previous_day</th>\n",
       "      <td>0.824561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_differences</th>\n",
       "      <td>0.638596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y1000\n",
       "features_all             0.870175\n",
       "features_lasso           0.807018\n",
       "features_VIF             0.578947\n",
       "features_biology         0.684211\n",
       "features_no_correlation  0.849123\n",
       "features_same_day        0.705263\n",
       "features_previous_day    0.824561\n",
       "features_differences     0.638596"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = auc_test_scores, index = feature_set_names, columns = ['y1000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll repeat the above, except using logistic regression. For comparison purposes, I will perform a similar analysis in R using more 'statistically sound' assumptions than here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   47.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   55.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "# Using y100 as the threshold:\n",
    "\n",
    "y100_auc_test_scores = []\n",
    "y100_models = {}\n",
    "\n",
    "for features, name in zip(feature_sets, feature_set_names):\n",
    "    num_features = [i for i in features if i in numeric_features] # some function to select numeric features\n",
    "    cat_features = [i for i in features if i in categorical_features] # if this is a blank list, I believe that's fine\n",
    "    \n",
    "    # create preprocessor\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "    ])\n",
    "    \n",
    "    #if len(cat_features) > 0:   # check if cat_features is empty, as this may cause problems in the pipeline\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "     ])\n",
    "    \n",
    "    # question: what happens if there are no categorical features? - sort out in the debugging stage\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, num_features),\n",
    "        ('categorical', categorical_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    lr_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LogisticRegression(max_iter = 1000, random_state = 545))\n",
    "    ])\n",
    "\n",
    "    # I need to create\n",
    "    #   a dict of values I want to test in the random search\n",
    "    param_dist = {\n",
    "        'model__C'              : (0.0001, 0.001, 0.01, 0.1, 1, 10),\n",
    "        'model__class_weight'   : (None, 'balanced')\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV\n",
    "    grid_search_auc = GridSearchCV(lr_pipeline,\n",
    "                              param_grid=param_dist,\n",
    "                              cv = 10,\n",
    "                              scoring = 'roc_auc', # maximize auc score (ways to do multiplie criteria)\n",
    "                              verbose = 1)\n",
    "    \n",
    "    # obtain AUC values from each of the models\n",
    "    grid_search_auc.fit(X_trainvalid, y100_trainvalid) \n",
    "    auc_score = ()\n",
    "    auc_score = grid_search_auc.score(X_test, y100_test)\n",
    "    y100_auc_test_scores.append(auc_score)\n",
    "    \n",
    "    # save models in a dict\n",
    "    model = ()\n",
    "    model = grid_search_auc.best_estimator_.steps[1][1]\n",
    "    y100_models.update({name: model})\n",
    "\n",
    "    y100_auc_test_scores\n",
    "    y100_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features_all</th>\n",
       "      <td>0.560588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_lasso</th>\n",
       "      <td>0.630355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_VIF</th>\n",
       "      <td>0.614443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_biology</th>\n",
       "      <td>0.504284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_no_correlation</th>\n",
       "      <td>0.564259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_same_day</th>\n",
       "      <td>0.556916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_previous_day</th>\n",
       "      <td>0.492044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_differences</th>\n",
       "      <td>0.348837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             y100\n",
       "features_all             0.560588\n",
       "features_lasso           0.630355\n",
       "features_VIF             0.614443\n",
       "features_biology         0.504284\n",
       "features_no_correlation  0.564259\n",
       "features_same_day        0.556916\n",
       "features_previous_day    0.492044\n",
       "features_differences     0.348837"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = y100_auc_test_scores, index = feature_set_names, columns = ['y100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03069227, -0.00668799,  0.00551904, -0.01388936, -0.00155577,\n",
       "         0.0033717 , -0.00600539,  0.00674386,  0.00901604, -0.0099779 ,\n",
       "         0.01100638, -0.00643611,  0.01697477,  0.01182141, -0.00300594,\n",
       "         0.01473761, -0.00185578, -0.00642211,  0.00536242, -0.01087142,\n",
       "         0.00414917, -0.01522889, -0.00519809,  0.00693077, -0.01373655,\n",
       "        -0.00930475,  0.00373999, -0.01317022,  0.0063235 ,  0.00403352,\n",
       "         0.00095481, -0.0028152 , -0.00834558,  0.01257983, -0.00282413,\n",
       "         0.01561435,  0.01032244,  0.00064386,  0.00981983,  0.00217304,\n",
       "        -0.00854457, -0.02000045, -0.00185063,  0.01146107, -0.00854201,\n",
       "         0.01719726,  0.0048754 , -0.01347158,  0.01558389,  0.01502842,\n",
       "        -0.00232569,  0.01709551,  0.00110877, -0.00139911,  0.00237499,\n",
       "         0.00299759, -0.00838348,  0.01050581, -0.00582225, -0.00648019,\n",
       "         0.00052012,  0.01099685, -0.00492811,  0.01405161,  0.01057914,\n",
       "        -0.00137551,  0.0116302 ,  0.0056361 , -0.00743507,  0.0127625 ,\n",
       "        -0.01022966, -0.01022966]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y100_models['features_all'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try for y200:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   46.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   13.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   54.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "# as above for threshold = 200 spores per day:\n",
    "\n",
    "y200_auc_test_scores = []\n",
    "y200_models = {}\n",
    "\n",
    "for features, name in zip(feature_sets, feature_set_names):\n",
    "    num_features = [i for i in features if i in numeric_features] \n",
    "    cat_features = [i for i in features if i in categorical_features] \n",
    "    \n",
    "    # create preprocessor\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "     ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, num_features),\n",
    "        ('categorical', categorical_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    lr_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LogisticRegression(max_iter = 1000, random_state = 545))\n",
    "    ])\n",
    "\n",
    "    # I need to create\n",
    "    #   a dict of values I want to test in the random search\n",
    "    param_dist = {\n",
    "        'model__C'              : (0.0001, 0.001, 0.01, 0.1, 1, 10),\n",
    "        'model__class_weight'   : (None, 'balanced')\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV\n",
    "    grid_search_auc = GridSearchCV(lr_pipeline,\n",
    "                              param_grid=param_dist,\n",
    "                              cv = 10,\n",
    "                              scoring = 'roc_auc', # maximize the auc score (ways to do multiplie criteria)\n",
    "                              verbose = 1)\n",
    "    \n",
    "    # obtain AUC values from each of the models\n",
    "    grid_search_auc.fit(X_trainvalid, y200_trainvalid) \n",
    "    auc_score = ()\n",
    "    auc_score = grid_search_auc.score(X_test, y200_test)\n",
    "    y200_auc_test_scores.append(auc_score)\n",
    "    \n",
    "    # save models in a dict\n",
    "    model = ()\n",
    "    model = grid_search_auc.best_estimator_.steps[1][1]\n",
    "    y200_models.update({name: model})\n",
    "\n",
    "    y200_auc_test_scores\n",
    "    y200_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features_all</th>\n",
       "      <td>0.537815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_lasso</th>\n",
       "      <td>0.568277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_VIF</th>\n",
       "      <td>0.522059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_biology</th>\n",
       "      <td>0.504202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_no_correlation</th>\n",
       "      <td>0.493697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_same_day</th>\n",
       "      <td>0.540966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_previous_day</th>\n",
       "      <td>0.536765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_differences</th>\n",
       "      <td>0.486345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             y200\n",
       "features_all             0.537815\n",
       "features_lasso           0.568277\n",
       "features_VIF             0.522059\n",
       "features_biology         0.504202\n",
       "features_no_correlation  0.493697\n",
       "features_same_day        0.540966\n",
       "features_previous_day    0.536765\n",
       "features_differences     0.486345"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = y200_auc_test_scores, index = feature_set_names, columns = ['y200'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still pretty bad values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   45.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   56.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Using y500 as the threshold:\n",
    "\n",
    "y500_auc_test_scores = []\n",
    "y500_models = {}\n",
    "\n",
    "for features, name in zip(feature_sets, feature_set_names):\n",
    "    num_features = [i for i in features if i in numeric_features] \n",
    "    cat_features = [i for i in features if i in categorical_features] \n",
    "    \n",
    "    # create preprocessor\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "     ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, num_features),\n",
    "        ('categorical', categorical_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    lr_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LogisticRegression(max_iter = 1000, random_state = 545))\n",
    "    ])\n",
    "\n",
    "    # I need to create\n",
    "    #   a dict of values I want to test in the random search\n",
    "    param_dist = {\n",
    "        'model__C'              : (0.0001, 0.001, 0.01, 0.1, 1, 10),\n",
    "        'model__class_weight'   : (None, 'balanced')\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV\n",
    "    grid_search_auc = GridSearchCV(lr_pipeline,\n",
    "                              param_grid=param_dist,\n",
    "                              cv = 10,\n",
    "                              scoring = 'roc_auc', # maximize the auc score (ways to do multiplie criteria)\n",
    "                              verbose = 1)\n",
    "    \n",
    "    # obtain AUC values from each of the models\n",
    "    grid_search_auc.fit(X_trainvalid, y500_trainvalid) \n",
    "    auc_score = ()\n",
    "    auc_score = grid_search_auc.score(X_test, y500_test)\n",
    "    y500_auc_test_scores.append(auc_score)\n",
    "    \n",
    "    # save models in a dict\n",
    "    model = ()\n",
    "    model = grid_search_auc.best_estimator_.steps[1][1]\n",
    "    y500_models.update({name: model})\n",
    "\n",
    "    y500_auc_test_scores\n",
    "    y500_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features_all</th>\n",
       "      <td>0.523098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_lasso</th>\n",
       "      <td>0.644022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_VIF</th>\n",
       "      <td>0.523098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_biology</th>\n",
       "      <td>0.523098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_no_correlation</th>\n",
       "      <td>0.535326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_same_day</th>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_previous_day</th>\n",
       "      <td>0.514946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_differences</th>\n",
       "      <td>0.480978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             y500\n",
       "features_all             0.523098\n",
       "features_lasso           0.644022\n",
       "features_VIF             0.523098\n",
       "features_biology         0.523098\n",
       "features_no_correlation  0.535326\n",
       "features_same_day        0.562500\n",
       "features_previous_day    0.514946\n",
       "features_differences     0.480978"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = y500_auc_test_scores, index = feature_set_names, columns = ['y500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   45.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   51.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "# as above for threshold = 1,000 spores per day:\n",
    "\n",
    "y1000_auc_test_scores = []\n",
    "y1000_models = {}\n",
    "\n",
    "for features, name in zip(feature_sets, feature_set_names):\n",
    "    num_features = [i for i in features if i in numeric_features] \n",
    "    cat_features = [i for i in features if i in categorical_features] \n",
    "    \n",
    "    # create preprocessor\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "     ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, num_features),\n",
    "        ('categorical', categorical_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    lr_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LogisticRegression(max_iter = 1000, random_state = 545))\n",
    "    ])\n",
    "\n",
    "    # I need to create\n",
    "    #   a dict of values I want to test in the random search\n",
    "    param_dist = {\n",
    "        'model__C'              : (0.0001, 0.001, 0.01, 0.1, 1, 10),\n",
    "        'model__class_weight'   : (None, 'balanced')\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV\n",
    "    grid_search_auc = GridSearchCV(lr_pipeline,\n",
    "                              param_grid=param_dist,\n",
    "                              cv = 10,\n",
    "                              scoring = 'roc_auc', # maximize the auc score (ways to do multiplie criteria)\n",
    "                              verbose = 1)\n",
    "    \n",
    "    # obtain AUC values from each of the models\n",
    "    grid_search_auc.fit(X_trainvalid, y1000_trainvalid) \n",
    "    auc_score = ()\n",
    "    auc_score = grid_search_auc.score(X_test, y1000_test)\n",
    "    y1000_auc_test_scores.append(auc_score)\n",
    "    \n",
    "    # save models in a dict\n",
    "    model = ()\n",
    "    model = grid_search_auc.best_estimator_.steps[1][1]\n",
    "    y1000_models.update({name: model})\n",
    "\n",
    "    y1000_auc_test_scores\n",
    "    y1000_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features_all</th>\n",
       "      <td>0.729825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_lasso</th>\n",
       "      <td>0.803509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_VIF</th>\n",
       "      <td>0.719298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_biology</th>\n",
       "      <td>0.656140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_no_correlation</th>\n",
       "      <td>0.708772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_same_day</th>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_previous_day</th>\n",
       "      <td>0.796491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features_differences</th>\n",
       "      <td>0.694737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y1000\n",
       "features_all             0.729825\n",
       "features_lasso           0.803509\n",
       "features_VIF             0.719298\n",
       "features_biology         0.656140\n",
       "features_no_correlation  0.708772\n",
       "features_same_day        0.684211\n",
       "features_previous_day    0.796491\n",
       "features_differences     0.694737"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = y1000_auc_test_scores, index = feature_set_names, columns = ['y1000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration of how AUC values are calculated:\n",
    "Try the last model from above, but this time explicitly calculate the AUC to see how they compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   48.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   52.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Using y1000 as the threshold:\n",
    "\n",
    "y1000_auc_test_scores_2 = []\n",
    "calculated_auc = []\n",
    "y1000_models_2 = {}\n",
    "\n",
    "for features, name in zip(feature_sets, feature_set_names):\n",
    "    # create numeric and categorical feature lists for pipeline - these are based on the selected ones from\n",
    "    #     above\n",
    "    num_features = [i for i in features if i in numeric_features] # some function to select numeric features\n",
    "    cat_features = [i for i in features if i in categorical_features] # if this is a blank list, I believe that's fine\n",
    "    \n",
    "    # create preprocessor\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('imputer', IterativeImputer(sample_posterior = True, random_state = 356))\n",
    "    ])\n",
    "    \n",
    "    #if len(cat_features) > 0:   # check if cat_features is empty, as this may cause problems in the pipeline\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(sparse=False, handle_unknown='error', drop = 'first')),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "     ])\n",
    "    \n",
    "    # question: what happens if there are no categorical features? - sort out in the debugging stage\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, num_features),\n",
    "        ('categorical', categorical_transformer, cat_features)\n",
    "    ])\n",
    "    \n",
    "    lr_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LogisticRegression(max_iter = 1000, random_state = 545))\n",
    "    ])\n",
    "\n",
    "    # I need to create\n",
    "    #   a dict of values I want to test in the random search\n",
    "    param_dist = {\n",
    "        'model__C'              : (0.0001, 0.001, 0.01, 0.1, 1, 10),\n",
    "        'model__class_weight'   : (None, 'balanced')\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV\n",
    "    grid_search_auc = GridSearchCV(lr_pipeline,\n",
    "                              param_grid=param_dist,\n",
    "                              cv = 10,\n",
    "                              scoring = 'roc_auc', # maximize the f1 score (ways to do multiplie criteria)\n",
    "                              verbose = 1)\n",
    "    \n",
    "    # obtain AUC values from each of the models\n",
    "    grid_search_auc.fit(X_trainvalid, y1000_trainvalid) \n",
    "    auc_score = ()\n",
    "    auc_score = grid_search_auc.score(X_test, y1000_test)\n",
    "    y1000_auc_test_scores_2.append(auc_score)\n",
    "    \n",
    "    AUC = ()\n",
    "    y_proba = ()\n",
    "    y_proba = grid_search_auc.predict_proba(X_test)[:,1]\n",
    "    AUC = roc_auc_score(y1000_test, y_proba)\n",
    "    calculated_auc.append(AUC)\n",
    "    \n",
    "    # save models in a dict\n",
    "    model = ()\n",
    "    model = grid_search_auc.best_estimator_.steps[1][1]\n",
    "    y1000_models_2.update({name: model})\n",
    "\n",
    "    #y1000_auc_test_scores\n",
    "    #y1000_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7298245614035088,\n",
       " 0.7929824561403509,\n",
       " 0.7403508771929824,\n",
       " 0.656140350877193,\n",
       " 0.7087719298245614,\n",
       " 0.6491228070175439,\n",
       " 0.8210526315789473,\n",
       " 0.6771929824561403]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculated_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7298245614035088,\n",
       " 0.8035087719298246,\n",
       " 0.7192982456140351,\n",
       " 0.656140350877193,\n",
       " 0.7087719298245614,\n",
       " 0.6842105263157895,\n",
       " 0.7964912280701755,\n",
       " 0.6947368421052632]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1000_auc_test_scores_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK... These are close-ish, but still different. Differences due to randomness somewhere or what?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
